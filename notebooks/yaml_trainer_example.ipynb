{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c09ada8f",
   "metadata": {},
   "source": [
    "# Arbor YAML Trainer Tutorial with Live Dashboard\n",
    "\n",
    "This notebook demonstrates how to use the Arbor YAML training system with adaptive context windows and **real-time monitoring dashboard**. We'll show you how to:\n",
    "\n",
    "1. **Create and customize training configurations**\n",
    "2. **Train models with dynamic growth and adaptive context**\n",
    "3. **Monitor training progress with live dashboard visualization**\n",
    "4. **Track model architecture changes in real-time**\n",
    "5. **Set up alerts and performance monitoring**\n",
    "6. **Test the trained model with different task types**\n",
    "\n",
    "## üÜï **New Dashboard Features:**\n",
    "\n",
    "- **üìä Live Metrics**: Real-time training loss, learning rate, and gradient monitoring\n",
    "- **üèóÔ∏è Architecture Visualization**: Interactive model structure with layer utilization heatmaps\n",
    "- **üå± Growth Tracking**: Timeline of parameter and layer growth events\n",
    "- **üîî Alert System**: Automatic notifications for training anomalies and milestones\n",
    "- **üìà Analytics**: Performance statistics, trends, and exportable reports\n",
    "\n",
    "The YAML trainer with Arbor dashboard makes it incredibly easy to train and monitor adaptive transformer models!\n",
    "\n",
    "## üöÄ **Quick Start:**\n",
    "1. Run this notebook to configure training\n",
    "2. Start the dashboard: `streamlit run arbor/tracking/dashboard.py`\n",
    "3. Watch your model train and grow in real-time at http://localhost:8501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbd5f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Add arbor to path\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "# Import Arbor tracking system\n",
    "try:\n",
    "    from arbor.tracking import TrainingMonitor\n",
    "    print(\"‚úÖ Arbor tracking system imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Arbor tracking not available: {e}\")\n",
    "\n",
    "# Check if we're in the right directory\n",
    "if not Path(\"arbor\").exists():\n",
    "    print(\"‚ùå Please run this notebook from the arbor-o1-living-ai root directory\")\n",
    "    print(\"Current directory:\", Path.cwd())\n",
    "else:\n",
    "    print(\"‚úÖ Found arbor directory\")\n",
    "    print(\"üìç Working directory:\", Path.cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40776a90",
   "metadata": {},
   "source": [
    "## Step 1: Create Your Training Configuration\n",
    "\n",
    "The YAML trainer uses configuration files to specify everything about your training run. Let's start by examining and customizing a training configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a72895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the example configuration first\n",
    "config_path = Path(\"configs/example_config.yaml\")\n",
    "\n",
    "if config_path.exists():\n",
    "    with open(config_path, 'r') as f:\n",
    "        config_content = f.read()\n",
    "    \n",
    "    print(\"üìã Example Configuration Structure:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Show first 30 lines to get an overview\n",
    "    lines = config_content.split('\\n')\n",
    "    for i, line in enumerate(lines[:30]):\n",
    "        print(f\"{i+1:2d}: {line}\")\n",
    "    \n",
    "    if len(lines) > 30:\n",
    "        print(f\"... ({len(lines) - 30} more lines)\")\n",
    "else:\n",
    "    print(\"‚ùå Example config not found. Let's create one!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15cdd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "    'logging': {\n",
    "        'arbor_tracking': {\n",
    "            'enabled': True,\n",
    "            'save_dir': './training_logs',\n",
    "            'update_interval': 1.0,\n",
    "            'dashboard_port': 8501,\n",
    "            'alerts': {\n",
    "                'enabled': True,\n",
    "                'email_notifications': False,  # Set to True and configure for email alerts\n",
    "                'webhook_url': None  # Add webhook URL for notifications\n",
    "            }\n",
    "        },\n",
    "        'console': {\n",
    "            'enabled': True,\n",
    "            'level': 'INFO'\n",
    "        }\n",
    "    },"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b177fc01",
   "metadata": {},
   "source": [
    "## Step 2: Understanding the YAML Configuration\n",
    "\n",
    "Let's examine the key sections of our configuration and what they control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5657bc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore each section of our configuration\n",
    "print(\"üîç Configuration Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Model configuration\n",
    "model_config = tutorial_config['model']\n",
    "print(\"\\nü§ñ MODEL CONFIGURATION:\")\n",
    "print(f\"   Vocabulary: {model_config['vocab_size']:,} tokens (Hermes-4-405B)\")\n",
    "print(f\"   Architecture: {model_config['num_layers']} layers √ó {model_config['hidden_size']} dim\")\n",
    "print(f\"   Parameters: ~{(model_config['hidden_size'] * model_config['num_layers'] * 4) / 1e6:.0f}M\")\n",
    "\n",
    "# Growth settings\n",
    "growth = model_config['growth']\n",
    "print(f\"\\nüå± GROWTH SETTINGS:\")\n",
    "print(f\"   Enabled: {growth['enabled']}\")\n",
    "print(f\"   Growth factor: {growth['factor']}x\")\n",
    "print(f\"   Max growth steps: {growth['max_steps']}\")\n",
    "print(f\"   Trigger threshold: {growth['threshold']}\")\n",
    "\n",
    "# Adaptive context\n",
    "adaptive = model_config['adaptive_context']\n",
    "print(f\"\\nüß† ADAPTIVE CONTEXT:\")\n",
    "print(f\"   Enabled: {adaptive['enabled']}\")\n",
    "print(f\"   Context range: {adaptive['min_context_length']:,} - {adaptive['max_context_length']:,}\")\n",
    "print(f\"   Task types: {len(adaptive['task_types'])} ({', '.join(adaptive['task_types'])})\")\n",
    "print(f\"   Context options: {len(adaptive['context_lengths'])} levels\")\n",
    "\n",
    "# Datasets\n",
    "datasets = tutorial_config['datasets']\n",
    "print(f\"\\nüìö DATASETS:\")\n",
    "for i, dataset in enumerate(datasets, 1):\n",
    "    print(f\"   {i}. {dataset['name']}: {dataset['source']} ({dataset['split']})\")\n",
    "    print(f\"      Max length: {dataset['preprocessing']['max_length']} tokens\")\n",
    "\n",
    "# Tracking and logging\n",
    "logging_config = tutorial_config['logging']\n",
    "print(f\"\\nüìä ARBOR TRACKING & LOGGING:\")\n",
    "arbor_tracking = logging_config['arbor_tracking']\n",
    "print(f\"   Dashboard enabled: {arbor_tracking['enabled']}\")\n",
    "print(f\"   Save directory: {arbor_tracking['save_dir']}\")\n",
    "print(f\"   Dashboard port: {arbor_tracking['dashboard_port']}\")\n",
    "print(f\"   Live monitoring: {arbor_tracking['update_interval']}s intervals\")\n",
    "print(f\"   Alerts enabled: {arbor_tracking['alerts']['enabled']}\")\n",
    "print(f\"   Console logging: {logging_config['console']['enabled']} ({logging_config['console']['level']})\")\n",
    "\n",
    "# Training\n",
    "training = tutorial_config['training']\n",
    "print(f\"\\nüéØ TRAINING:\")\n",
    "print(f\"   Learning rate: {training['learning_rate']}\")\n",
    "print(f\"   Batch size: {training['per_device_train_batch_size']} √ó {training['gradient_accumulation_steps']} = {training['per_device_train_batch_size'] * training['gradient_accumulation_steps']}\")\n",
    "print(f\"   Total steps: {len(datasets)} √ó {training['steps_per_dataset']} = {len(datasets) * training['steps_per_dataset']}\")\n",
    "print(f\"   Mixed precision: {training['fp16']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c365cf",
   "metadata": {},
   "source": [
    "## Step 3: Initialize the YAML Trainer\n",
    "\n",
    "Now let's create and initialize the YAML trainer with our configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eaed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the YAML trainer\n",
    "try:\n",
    "    from arbor.train.yaml_trainer import ArborYAMLTrainer\n",
    "    print(\"‚úÖ Successfully imported ArborYAMLTrainer\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"Make sure you're in the correct directory and arbor is in the path\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b52b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the trainer\n",
    "print(\"üöÄ Initializing YAML Trainer...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    trainer = ArborYAMLTrainer(str(tutorial_config_path))\n",
    "    print(\"‚úÖ Trainer initialized successfully!\")\n",
    "    \n",
    "    # The trainer automatically validates the configuration\n",
    "    print(\"\\nüìã Configuration loaded and validated\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Trainer initialization failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6da191e",
   "metadata": {},
   "source": [
    "## Step 4: Setup Components\n",
    "\n",
    "The trainer needs to setup several components before training. Let's do this step by step to see what's happening:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a464b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4a: Setup tokenizer\n",
    "print(\"üì• Setting up tokenizer...\")\n",
    "try:\n",
    "    trainer.setup_tokenizer()\n",
    "    print(f\"‚úÖ Tokenizer ready: {len(trainer.tokenizer):,} vocabulary\")\n",
    "    \n",
    "    # Test the tokenizer\n",
    "    test_text = \"Hello, this is a test of the Hermes tokenizer!\"\n",
    "    tokens = trainer.tokenizer.encode(test_text)\n",
    "    print(f\"üß™ Test encoding: '{test_text}' ‚Üí {len(tokens)} tokens\")\n",
    "    print(f\"   First 10 tokens: {tokens[:10]}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Tokenizer setup failed: {e}\")\n",
    "    print(\"This might be due to internet connectivity or HuggingFace access\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20447431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4b: Setup model\n",
    "print(\"\\nü§ñ Setting up Arbor model...\")\n",
    "try:\n",
    "    trainer.setup_model()\n",
    "    print(f\"‚úÖ Model created: {trainer.model.param_count():,} parameters\")\n",
    "    \n",
    "    # Show model architecture details\n",
    "    config = trainer.model.config\n",
    "    print(f\"\\nüìä Model details:\")\n",
    "    print(f\"   Architecture: {config.num_layers} layers\")\n",
    "    print(f\"   Hidden size: {config.dim}\")\n",
    "    print(f\"   Attention heads: {config.num_heads}\")\n",
    "    print(f\"   FFN dimension: {config.ffn_dim}\")\n",
    "    print(f\"   Max sequence length: {config.max_seq_length:,}\")\n",
    "    \n",
    "    # Show adaptive context info\n",
    "    if hasattr(trainer.model, 'get_context_info'):\n",
    "        context_info = trainer.model.get_context_info()\n",
    "        print(f\"\\nüß† Adaptive context info:\")\n",
    "        print(f\"   Enabled: {context_info['adaptive_context_enabled']}\")\n",
    "        if context_info['adaptive_context_enabled']:\n",
    "            print(f\"   Current context: {context_info['current_context_length']:,}\")\n",
    "            print(f\"   Context range: {context_info['min_context_length']:,} - {context_info['max_context_length']:,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Model setup failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab6fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4c: Load datasets\n",
    "print(\"\\nüìö Loading datasets...\")\n",
    "try:\n",
    "    trainer.load_datasets()\n",
    "    \n",
    "    print(f\"‚úÖ Datasets loaded: {len(trainer.datasets)}\")\n",
    "    \n",
    "    # Show dataset info\n",
    "    for name, dataset in trainer.datasets.items():\n",
    "        print(f\"\\nüìä Dataset: {name}\")\n",
    "        print(f\"   Size: {len(dataset):,} examples\")\n",
    "        \n",
    "        # Show a sample\n",
    "        if len(dataset) > 0:\n",
    "            sample = dataset[0]\n",
    "            input_ids = sample['input_ids']\n",
    "            decoded = trainer.tokenizer.decode(input_ids[:50])  # First 50 tokens\n",
    "            print(f\"   Sample: {decoded}...\")\n",
    "            print(f\"   Token length: {len(input_ids)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Dataset loading failed: {e}\")\n",
    "    print(\"This might be due to internet connectivity or dataset access issues\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c539c8f4",
   "metadata": {},
   "source": [
    "## Step 5: Training Setup\n",
    "\n",
    "Before we start training, let's setup logging and create the trainer objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22b9c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Arbor tracking and logging\n",
    "print(\"üìä Setting up Arbor tracking system...\")\n",
    "try:\n",
    "    # Initialize TrainingMonitor with configuration\n",
    "    tracking_config = tutorial_config['logging']['arbor_tracking']\n",
    "    \n",
    "    # Create training monitor\n",
    "    training_monitor = TrainingMonitor(\n",
    "        save_dir=tracking_config['save_dir'],\n",
    "        update_interval=tracking_config['update_interval']\n",
    "    )\n",
    "    \n",
    "    # Setup alert system if enabled\n",
    "    if tracking_config['alerts']['enabled']:\n",
    "        training_monitor.setup_alerts(\n",
    "            email_enabled=tracking_config['alerts']['email_notifications'],\n",
    "            webhook_url=tracking_config['alerts']['webhook_url']\n",
    "        )\n",
    "    \n",
    "    print(\"‚úÖ Arbor tracking system initialized\")\n",
    "    print(f\"   üìä Dashboard will be available at: http://localhost:{tracking_config['dashboard_port']}\")\n",
    "    print(f\"   üíæ Metrics saved to: {tracking_config['save_dir']}\")\n",
    "    print(f\"   üîî Alerts enabled: {tracking_config['alerts']['enabled']}\")\n",
    "    \n",
    "    # Setup traditional logging as well\n",
    "    trainer.setup_logging()\n",
    "    print(\"‚úÖ Console logging configured\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Tracking setup had issues: {e}\")\n",
    "    print(\"Training can continue with basic logging\")\n",
    "    # Fallback to basic logging\n",
    "    try:\n",
    "        trainer.setup_logging()\n",
    "        print(\"‚úÖ Basic logging configured\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è Even basic logging had issues - continuing anyway\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e02f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the Arbor Dashboard (optional)\n",
    "print(\"\\nüåê Starting Arbor Dashboard...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "dashboard_port = tutorial_config['logging']['arbor_tracking']['dashboard_port']\n",
    "\n",
    "print(\"To monitor training in real-time:\")\n",
    "print(\"1. üöÄ Option A - Use the launcher:\")\n",
    "print(\"   python launch_training_dashboard.py\")\n",
    "print()\n",
    "print(\"2. üìä Option B - Start dashboard manually:\")\n",
    "print(f\"   streamlit run arbor/tracking/dashboard.py --server.port={dashboard_port}\")\n",
    "print()\n",
    "print(\"3. üåê Then open your browser to:\")\n",
    "print(f\"   http://localhost:{dashboard_port}\")\n",
    "print()\n",
    "print(\"The dashboard will show:\")\n",
    "print(\"   ‚Ä¢ üìà Live training metrics (loss, learning rate)\")\n",
    "print(\"   ‚Ä¢ üèóÔ∏è Model architecture with layer utilization\")  \n",
    "print(\"   ‚Ä¢ üå± Growth tracking (parameters and layers)\")\n",
    "print(\"   ‚Ä¢ üîî Training alerts and notifications\")\n",
    "print(\"   ‚Ä¢ üìä Performance analytics and system monitoring\")\n",
    "print()\n",
    "print(\"üí° Tip: Start the dashboard in another terminal before running training!\")\n",
    "print(\"    The dashboard will automatically pick up training data as it's generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e943737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a trainer for the first dataset to inspect the setup\n",
    "if trainer.datasets:\n",
    "    dataset_name = list(trainer.datasets.keys())[0]\n",
    "    print(f\"üîß Creating trainer for dataset: {dataset_name}\")\n",
    "    \n",
    "    try:\n",
    "        hf_trainer = trainer.create_trainer(dataset_name)\n",
    "        print(f\"‚úÖ HuggingFace trainer created\")\n",
    "        print(f\"   Training dataset: {len(hf_trainer.train_dataset):,} examples\")\n",
    "        if hf_trainer.eval_dataset:\n",
    "            print(f\"   Eval dataset: {len(hf_trainer.eval_dataset):,} examples\")\n",
    "        \n",
    "        # Show training arguments\n",
    "        args = hf_trainer.args\n",
    "        print(f\"\\n‚öôÔ∏è  Training arguments:\")\n",
    "        print(f\"   Output dir: {args.output_dir}\")\n",
    "        print(f\"   Learning rate: {args.learning_rate}\")\n",
    "        print(f\"   Batch size: {args.per_device_train_batch_size}\")\n",
    "        print(f\"   Max steps: {args.max_steps}\")\n",
    "        print(f\"   Save steps: {args.save_steps}\")\n",
    "        print(f\"   Eval steps: {args.eval_steps}\")\n",
    "        print(f\"   FP16: {args.fp16}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Trainer creation failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8374699f",
   "metadata": {},
   "source": [
    "## Step 6: Test Adaptive Context System\n",
    "\n",
    "Before training, let's test the adaptive context system with different types of inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febb0659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the adaptive context system\n",
    "print(\"üß† Testing Adaptive Context System\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test different types of inputs\n",
    "test_inputs = {\n",
    "    \"simple_chat\": \"Hello! How are you today?\",\n",
    "    \n",
    "    \"code_task\": \"\"\"\n",
    "def fibonacci(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    else:\n",
    "        return fibonacci(n-1) + fibonacci(n-2)\n",
    "\n",
    "# This is a recursive implementation\n",
    "# Could be optimized with dynamic programming\n",
    "for i in range(10):\n",
    "    print(f\"fib({i}) = {fibonacci(i)}\")\n",
    "\"\"\",\n",
    "    \n",
    "    \"reasoning_task\": \"\"\"\n",
    "Let me think through this step by step. If we have a logical puzzle where:\n",
    "1. All cats are animals\n",
    "2. Some animals are pets  \n",
    "3. No pets are wild\n",
    "4. Some cats are wild\n",
    "\n",
    "We need to determine if there's a contradiction. Let me analyze each statement carefully\n",
    "and see if they can all be true simultaneously. This requires careful logical reasoning\n",
    "to avoid making invalid inferences.\n",
    "\"\"\",\n",
    "    \n",
    "    \"long_document\": \"\"\"\n",
    "This is a comprehensive research paper on machine learning that covers multiple aspects\n",
    "of the field. The introduction provides background on artificial intelligence and its\n",
    "historical development. The methodology section describes various approaches including\n",
    "supervised learning, unsupervised learning, and reinforcement learning paradigms.\n",
    "\"\"\" + \" The paper continues with detailed analysis.\" * 50  # Make it longer\n",
    "}\n",
    "\n",
    "# Test each input type\n",
    "for task_type, text in test_inputs.items():\n",
    "    print(f\"\\nüîç Testing: {task_type}\")\n",
    "    print(f\"Input length: {len(text)} characters\")\n",
    "    \n",
    "    # Tokenize the input\n",
    "    inputs = trainer.tokenizer(text, return_tensors=\"pt\", truncation=False)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    token_count = input_ids.shape[1]\n",
    "    print(f\"Token count: {token_count}\")\n",
    "    \n",
    "    # Get current context info\n",
    "    initial_context = trainer.model.get_context_info()['current_context_length']\n",
    "    \n",
    "    # Test the model (this should trigger adaptive context)\n",
    "    trainer.model.eval()\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            # This forward pass will trigger context adaptation\n",
    "            outputs = trainer.model(input_ids, return_dict=True)\n",
    "            \n",
    "            # Check if context adapted\n",
    "            final_context = trainer.model.get_context_info()['current_context_length']\n",
    "            \n",
    "            print(f\"Context: {initial_context:,} ‚Üí {final_context:,} tokens\")\n",
    "            if final_context != initial_context:\n",
    "                print(f\"‚úÖ Context adapted for {task_type}\")\n",
    "            else:\n",
    "                print(f\"‚Üí Context unchanged for {task_type}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {task_type}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc04629",
   "metadata": {},
   "source": [
    "## Step 7: Run Training\n",
    "\n",
    "Now let's run the actual training! We'll train for a short period to demonstrate the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33735d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: This will actually train the model!\n",
    "print(\"‚ö†Ô∏è  TRAINING WARNING\")\n",
    "print(\"=\" * 50)\n",
    "print(\"The next cell will run actual training.\")\n",
    "print(\"This may take several minutes and will:\")\n",
    "print(\"‚Ä¢ Download datasets from HuggingFace\")\n",
    "print(\"‚Ä¢ Train the model for 200 steps\")\n",
    "print(\"‚Ä¢ Show parameter growth during training\")\n",
    "print(\"‚Ä¢ Save model checkpoints\")\n",
    "print(\"\")\n",
    "print(\"Set RUN_TRAINING = True to proceed\")\n",
    "\n",
    "RUN_TRAINING = False  # Set to True to actually run training\n",
    "\n",
    "if RUN_TRAINING:\n",
    "    print(\"üöÄ Starting training pipeline...\")\n",
    "else:\n",
    "    print(\"üõë Training skipped (set RUN_TRAINING = True to run)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17ef955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training if enabled\n",
    "if RUN_TRAINING:\n",
    "    print(\"üöÄ Starting Arbor YAML Training Pipeline with Live Dashboard\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Start monitoring\n",
    "        if 'training_monitor' in locals():\n",
    "            training_monitor.start_monitoring()\n",
    "            print(\"üìä Training monitor started - metrics will be saved for dashboard\")\n",
    "        \n",
    "        # This runs the complete training pipeline\n",
    "        trainer.train()\n",
    "        \n",
    "        print(\"\\nüéâ Training completed successfully!\")\n",
    "        \n",
    "        # Show final model stats\n",
    "        final_params = trainer.model.param_count()\n",
    "        print(f\"üìä Final model size: {final_params:,} parameters\")\n",
    "        \n",
    "        # Show training outputs\n",
    "        output_dir = Path(trainer.config.training_config['output_dir'])\n",
    "        if output_dir.exists():\n",
    "            saved_models = list(output_dir.glob(\"*/\"))\n",
    "            print(f\"üíæ Saved {len(saved_models)} model checkpoints:\")\n",
    "            for model_dir in saved_models:\n",
    "                print(f\"   üìÅ {model_dir.name}\")\n",
    "        \n",
    "        # Stop monitoring and generate report\n",
    "        if 'training_monitor' in locals():\n",
    "            training_monitor.stop_monitoring()\n",
    "            report_file = training_monitor.export_training_report()\n",
    "            print(f\"üìÑ Training report saved: {report_file}\")\n",
    "            \n",
    "            dashboard_port = tutorial_config['logging']['arbor_tracking']['dashboard_port']\n",
    "            print(f\"\\nüåê View detailed metrics at: http://localhost:{dashboard_port}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Training failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        # Stop monitoring on error\n",
    "        if 'training_monitor' in locals():\n",
    "            training_monitor.stop_monitoring()\n",
    "        \n",
    "else:\n",
    "    # Simulate what training would show with Arbor tracking\n",
    "    print(\"üìã Training simulation (would show):\")\n",
    "    print(\"üå± Initialized Arbor trainer with config: configs/tutorial_config.yaml\")\n",
    "    print(\"\udcca Arbor tracking system initialized:\")\n",
    "    print(\"   ‚Ä¢ Dashboard ready at http://localhost:8501\")\n",
    "    print(\"   ‚Ä¢ Metrics saved to: ./training_logs\")\n",
    "    print(\"   ‚Ä¢ Real-time monitoring enabled\")\n",
    "    print(\"   ‚Ä¢ Alert system active\")\n",
    "    print(\"\ud83düì• Downloading fresh Hermes-4-405B tokenizer...\")\n",
    "    print(\"‚úÖ Successfully loaded fresh Hermes-4-405B tokenizer\")\n",
    "    print(\"‚úÖ Created Arbor model: 347,394,048 parameters\")\n",
    "    print(\"üß† Adaptive context enabled:\")\n",
    "    print(\"   Range: 512 - 32,768\")\n",
    "    print(\"   Supported tasks: 4\")\n",
    "    print(\"üå± Growth monitoring enabled:\")\n",
    "    print(\"   Factor: 1.5x\")\n",
    "    print(\"   Max steps: 4\")\n",
    "    print(\"üìö Loading datasets...\")\n",
    "    print(\"   ‚úÖ tiny_stories: 1,000 examples\")\n",
    "    print(\"   ‚úÖ code_samples: 500 examples\")\n",
    "    print(\"\")\n",
    "    print(\"üéØ Training on tiny_stories...\")\n",
    "    print(\"   üìä Dashboard: Real-time loss curves, layer utilization heatmaps\")\n",
    "    print(\"   üìä Parameters: 347,394,048 ‚Üí 347,894,048 (growth occurred)\")\n",
    "    print(\"   üîî Alert: Layer growth event detected\")\n",
    "    print(\"   ‚úÖ tiny_stories complete!\")\n",
    "    print(\"\")\n",
    "    print(\"üéØ Training on code_samples...\")\n",
    "    print(\"   üìä Dashboard: Architecture visualization updated\")\n",
    "    print(\"   üìä Parameters: 347,894,048 ‚Üí 348,394,048 (growth occurred)\")\n",
    "    print(\"   üîî Alert: Performance threshold reached\")\n",
    "    print(\"   ‚úÖ code_samples complete!\")\n",
    "    print(\"\")\n",
    "    print(\"üéâ Training pipeline complete!\")\n",
    "    print(\"üìä Final dashboard shows comprehensive training analytics\")\n",
    "    print(\"üìÑ Training report exported with growth timeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbfa1c1",
   "metadata": {},
   "source": [
    "## Step 8: Test the Trained Model\n",
    "\n",
    "Let's test our model (or demonstrate what testing would look like) with different task types to see how the adaptive context system works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693bfd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model generation with different tasks\n",
    "print(\"üß™ Testing Trained Model\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "test_prompts = {\n",
    "    \"story\": \"Once upon a time, in a magical forest\",\n",
    "    \"code\": \"# Python function to calculate factorial\\ndef factorial(n):\",\n",
    "    \"reasoning\": \"Let me solve this step by step. The problem is:\",\n",
    "    \"chat\": \"User: What's the weather like today?\\nAssistant:\"\n",
    "}\n",
    "\n",
    "for task_type, prompt in test_prompts.items():\n",
    "    print(f\"\\nüéØ Testing {task_type} task:\")\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    \n",
    "    # Tokenize prompt\n",
    "    inputs = trainer.tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    \n",
    "    # Show what would happen with adaptive context\n",
    "    print(f\"Input tokens: {input_ids.shape[1]}\")\n",
    "    \n",
    "    if RUN_TRAINING:\n",
    "        # Actually test the trained model\n",
    "        trainer.model.eval()\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                # Generate response\n",
    "                generated = trainer.model.generate(\n",
    "                    input_ids,\n",
    "                    max_new_tokens=50,\n",
    "                    temperature=0.7,\n",
    "                    do_sample=True\n",
    "                )\n",
    "                \n",
    "                # Decode response\n",
    "                response = trainer.tokenizer.decode(generated[0], skip_special_tokens=True)\n",
    "                print(f\"Generated: {response[len(prompt):]}\")\n",
    "                \n",
    "                # Show context info\n",
    "                context_info = trainer.model.get_context_info()\n",
    "                print(f\"Context used: {context_info['current_context_length']:,} tokens\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Generation failed: {e}\")\n",
    "    else:\n",
    "        # Simulate what would happen\n",
    "        simulated_contexts = {\"story\": 2048, \"code\": 4096, \"reasoning\": 8192, \"chat\": 1024}\n",
    "        print(f\"Would adapt context to: {simulated_contexts[task_type]:,} tokens\")\n",
    "        print(f\"Would generate appropriate {task_type} response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c46680c",
   "metadata": {},
   "source": [
    "## Step 9: Configuration Tips and Best Practices\n",
    "\n",
    "Here are some tips for customizing your YAML training configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd33aa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration tips and best practices\n",
    "print(\"üí° YAML Configuration Tips\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "tips = {\n",
    "    \"Model Size\": {\n",
    "        \"Small (100M)\": \"hidden_size: 512, num_layers: 12\",\n",
    "        \"Medium (500M)\": \"hidden_size: 1024, num_layers: 24\", \n",
    "        \"Large (1B)\": \"hidden_size: 1536, num_layers: 32\"\n",
    "    },\n",
    "    \n",
    "    \"Context Lengths\": {\n",
    "        \"Short tasks\": \"max 4K tokens (chat, Q&A)\",\n",
    "        \"Medium tasks\": \"4K-16K tokens (code, creative)\",\n",
    "        \"Long tasks\": \"16K+ tokens (documents, reasoning)\"\n",
    "    },\n",
    "    \n",
    "    \"Growth Settings\": {\n",
    "        \"Conservative\": \"factor: 1.25, threshold: 0.95\",\n",
    "        \"Moderate\": \"factor: 1.5, threshold: 0.9\",\n",
    "        \"Aggressive\": \"factor: 2.0, threshold: 0.85\"\n",
    "    },\n",
    "    \n",
    "    \"Training Speed\": {\n",
    "        \"Fast prototyping\": \"small datasets, few steps\",\n",
    "        \"Full training\": \"complete datasets, many steps\", \n",
    "        \"Production\": \"multiple epochs, careful validation\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for category, options in tips.items():\n",
    "    print(f\"\\nüîß {category}:\")\n",
    "    for option, description in options.items():\n",
    "        print(f\"   {option}: {description}\")\n",
    "\n",
    "print(f\"\\nüìã Common YAML patterns:\")\n",
    "print(\"\"\"\n",
    "# Full monitoring setup for research\n",
    "adaptive_context: \n",
    "  enabled: true\n",
    "growth:\n",
    "  enabled: true\n",
    "logging:\n",
    "  arbor_tracking:\n",
    "    enabled: true\n",
    "    save_dir: './training_logs'\n",
    "    dashboard_port: 8501\n",
    "    alerts:\n",
    "      enabled: true\n",
    "\n",
    "# Minimal setup for testing  \n",
    "adaptive_context:\n",
    "  enabled: false\n",
    "growth:\n",
    "  enabled: false\n",
    "logging:\n",
    "  arbor_tracking:\n",
    "    enabled: false\n",
    "  console:\n",
    "    enabled: true\n",
    "datasets:\n",
    "  - name: \"test\"\n",
    "    source: \"roneneldan/TinyStories\"\n",
    "    split: \"train[:100]\"\n",
    "\n",
    "# Production setup with full tracking\n",
    "logging:\n",
    "  arbor_tracking:\n",
    "    enabled: true\n",
    "    save_dir: './production_logs'\n",
    "    update_interval: 0.5\n",
    "    dashboard_port: 8501\n",
    "    alerts:\n",
    "      enabled: true\n",
    "      email_notifications: true\n",
    "      webhook_url: \"https://your-webhook-url.com\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f97ae4e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've learned how to use the Arbor YAML training system with real-time monitoring. Here's what we covered:\n",
    "\n",
    "### ‚úÖ **What You Learned:**\n",
    "\n",
    "1. **üìã YAML Configuration** - How to create and customize training configs\n",
    "2. **üß† Adaptive Context** - Task-aware context window adaptation  \n",
    "3. **üå± Dynamic Growth** - Parameter expansion during training\n",
    "4. **üöÄ Easy Training** - One-command training with `python train.py config.yaml`\n",
    "5. **üìä Live Monitoring** - Real-time dashboard with training visualization\n",
    "6. **üß™ Testing & Validation** - How to test trained models\n",
    "\n",
    "### üéØ **Key Benefits:**\n",
    "\n",
    "- **Simple**: Just edit YAML, no complex code\n",
    "- **Powerful**: Full control over model architecture and training\n",
    "- **Smart**: Automatic context adaptation and parameter growth\n",
    "- **Visual**: Real-time dashboard with live metrics and architecture visualization\n",
    "- **Production Ready**: HuggingFace integration and comprehensive monitoring\n",
    "\n",
    "### üöÄ **Next Steps:**\n",
    "\n",
    "1. **Customize** your own YAML config for your use case\n",
    "2. **Train** with real datasets for your domain\n",
    "3. **Monitor** training with the Arbor dashboard at http://localhost:8501\n",
    "4. **Deploy** trained models to HuggingFace Hub\n",
    "\n",
    "### üìä **Dashboard Features:**\n",
    "\n",
    "- **Live Metrics**: Training loss, learning rate, gradient norms in real-time\n",
    "- **Architecture View**: Interactive model visualization with layer utilization\n",
    "- **Growth Tracking**: Parameter and layer growth timeline\n",
    "- **Alert System**: Automatic notifications for training events\n",
    "- **Analytics**: Performance statistics and comprehensive reports\n",
    "\n",
    "The YAML trainer with Arbor dashboard makes it incredibly easy to experiment with cutting-edge transformer architectures while monitoring everything in real-time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c65eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup and final info\n",
    "print(\"üßπ Cleanup and Final Info\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Show created files\n",
    "created_files = [\n",
    "    \"configs/tutorial_config.yaml\",\n",
    "    \"training_logs/\" if 'training_monitor' in locals() else \"training_logs/ (would be created)\",\n",
    "    \"tutorial_output/\" if RUN_TRAINING else \"tutorial_output/ (would be created)\"\n",
    "]\n",
    "\n",
    "print(\"üìÅ Files created during this tutorial:\")\n",
    "for file in created_files:\n",
    "    if Path(file).exists() or \"would be\" in file:\n",
    "        print(f\"   ‚úÖ {file}\")\n",
    "\n",
    "dashboard_port = tutorial_config['logging']['arbor_tracking']['dashboard_port']\n",
    "\n",
    "print(f\"\\nüéØ To run training yourself:\")\n",
    "print(f\"   1. Set RUN_TRAINING = True in cell 16\")\n",
    "print(f\"   2. Or run: python train.py configs/tutorial_config.yaml\")\n",
    "\n",
    "print(f\"\\nüåê To access the Arbor Dashboard:\")\n",
    "print(f\"   1. Start dashboard: streamlit run arbor/tracking/dashboard.py --server.port={dashboard_port}\")\n",
    "print(f\"   2. Open browser: http://localhost:{dashboard_port}\")\n",
    "print(f\"   3. Or use launcher: python launch_training_dashboard.py\")\n",
    "\n",
    "print(f\"\\nüìä Dashboard Features:\")\n",
    "print(f\"   ‚Ä¢ Live training metrics with real-time updates\")\n",
    "print(f\"   ‚Ä¢ Interactive model architecture visualization\")\n",
    "print(f\"   ‚Ä¢ Parameter and layer growth tracking\")\n",
    "print(f\"   ‚Ä¢ Alert system with configurable notifications\")\n",
    "print(f\"   ‚Ä¢ Performance analytics and export capabilities\")\n",
    "\n",
    "print(f\"\\nüîß To customize:\")\n",
    "print(f\"   1. Edit configs/tutorial_config.yaml\")\n",
    "print(f\"   2. Adjust model size, datasets, training steps\")\n",
    "print(f\"   3. Enable/disable adaptive context and growth\")\n",
    "print(f\"   4. Configure dashboard alerts and monitoring\")\n",
    "\n",
    "print(f\"\\nüìö For more examples:\")\n",
    "print(f\"   ‚Ä¢ Check configs/example_config.yaml\")\n",
    "print(f\"   ‚Ä¢ Run python examples/training_with_dashboard.py\")\n",
    "print(f\"   ‚Ä¢ See COMPLETE_USAGE_GUIDE.md for full documentation\")\n",
    "\n",
    "print(f\"\\nüå± Happy training with Arbor and live monitoring!\")\n",
    "print(f\"üöÄ The future of adaptive AI training is here!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
