{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c09ada8f",
   "metadata": {},
   "source": [
    "# Arbor YAML Trainer Tutorial with Live Dashboard\n",
    "\n",
    "This notebook demonstrates how to use the Arbor YAML training system with adaptive context windows and **real-time monitoring dashboard**. Works perfectly in both **local environments** and **Google Colab** with public URL access!\n",
    "\n",
    "## ğŸ¯ **What You'll Learn:**\n",
    "\n",
    "1. **Create and customize training configurations**\n",
    "2. **Train models with dynamic growth and adaptive context**\n",
    "3. **Monitor training progress with live dashboard visualization**\n",
    "4. **Track model architecture changes in real-time**\n",
    "5. **Set up alerts and performance monitoring**\n",
    "6. **Test the trained model with different task types**\n",
    "\n",
    "## ğŸ†• **Dashboard Features:**\n",
    "\n",
    "- **ğŸ“Š Live Metrics**: Real-time training loss, learning rate, and gradient monitoring\n",
    "- **ğŸ—ï¸ Architecture Visualization**: Interactive model structure with layer utilization heatmaps\n",
    "- **ğŸŒ± Growth Tracking**: Timeline of parameter and layer growth events\n",
    "- **ğŸ”” Alert System**: Automatic notifications for training anomalies and milestones\n",
    "- **ğŸ“ˆ Analytics**: Performance statistics, trends, and exportable reports\n",
    "\n",
    "## ğŸŒ **Environment Support:**\n",
    "\n",
    "### ğŸ’» **Local Development:**\n",
    "- Dashboard at `http://localhost:8501`\n",
    "- Full feature access\n",
    "- Private and secure\n",
    "\n",
    "### â˜ï¸ **Google Colab:**\n",
    "- **Public URL** via ngrok (e.g., `https://abc123.ngrok.io`)\n",
    "- **Mobile-responsive** dashboard\n",
    "- **Shareable** with team members\n",
    "- **Identical features** to local setup\n",
    "\n",
    "## ğŸš€ **Quick Start:**\n",
    "\n",
    "### Local:\n",
    "1. Run this notebook to configure training\n",
    "2. Start dashboard: `streamlit run arbor/tracking/dashboard.py`\n",
    "3. Monitor at http://localhost:8501\n",
    "\n",
    "### Google Colab:\n",
    "1. Run environment setup cells (auto-detects Colab)\n",
    "2. Get free ngrok token from [ngrok.com](https://ngrok.com)\n",
    "3. Run dashboard startup cell with your token\n",
    "4. Monitor at your unique public URL!\n",
    "\n",
    "The YAML trainer with Arbor dashboard makes adaptive transformer training accessible everywhere! ğŸŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbd5f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Add arbor to path\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "# Import Arbor tracking system\n",
    "try:\n",
    "    from arbor.tracking import TrainingMonitor\n",
    "    print(\"âœ… Arbor tracking system imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"âš ï¸ Arbor tracking not available: {e}\")\n",
    "\n",
    "# Check if we're in the right directory\n",
    "if not Path(\"arbor\").exists():\n",
    "    print(\"âŒ Please run this notebook from the arbor-o1-living-ai root directory\")\n",
    "    print(\"Current directory:\", Path.cwd())\n",
    "else:\n",
    "    print(\"âœ… Found arbor directory\")\n",
    "    print(\"ğŸ“ Working directory:\", Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96b05bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Dependencies\n",
    "print(\"ğŸ“¦ Installing Required Dependencies...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Core dependencies for Arbor training\n",
    "dependencies = [\n",
    "    \"torch>=2.0.0\",\n",
    "    \"transformers>=4.30.0\", \n",
    "    \"datasets>=2.14.0\",\n",
    "    \"accelerate>=0.20.0\",\n",
    "    \"peft>=0.4.0\",\n",
    "    \"bitsandbytes>=0.41.0\",\n",
    "    \"streamlit>=1.25.0\",\n",
    "    \"plotly>=5.15.0\",\n",
    "    \"pyngrok>=6.0.0\",  # For Google Colab public URLs\n",
    "    \"tensorboard>=2.13.0\",\n",
    "    \"wandb>=0.15.0\",  # Optional but useful\n",
    "    \"scipy>=1.10.0\",\n",
    "    \"scikit-learn>=1.3.0\"\n",
    "]\n",
    "\n",
    "# Install other dependencies first\n",
    "print(\"\\nğŸ“¦ Installing core dependencies...\")\n",
    "for dep in dependencies:\n",
    "    try:\n",
    "        print(f\"   Installing {dep}...\")\n",
    "        !pip install -q {dep}\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸ Warning: Could not install {dep}: {e}\")\n",
    "\n",
    "print(\"\\nâœ… Core dependencies installed!\")\n",
    "\n",
    "# Now handle Arbor installation with improved logic\n",
    "print(\"\\nğŸŒ± Installing Arbor package...\")\n",
    "print(\"   Checking installation options...\")\n",
    "\n",
    "arbor_installed = False\n",
    "\n",
    "# Option 1: Try GitHub installation (most common failure point)\n",
    "print(\"\\nğŸ”— Attempting GitHub installation...\")\n",
    "try:\n",
    "    !pip install -q git+https://github.com/Noema-Research/Arbor.git\n",
    "    print(\"âœ… Arbor installed successfully from GitHub!\")\n",
    "    arbor_installed = True\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ GitHub installation failed: {e}\")\n",
    "    print(\"   This is common in cloud environments due to access restrictions\")\n",
    "\n",
    "# Option 2: Clone repo and install locally (for Colab)\n",
    "if not arbor_installed:\n",
    "    print(\"\\nğŸ“¥ Trying to clone repository for local installation...\")\n",
    "    try:\n",
    "        # Check if we're in Colab and need to clone\n",
    "        import os\n",
    "        if not os.path.exists(\"arbor-o1-living-ai\"):\n",
    "            print(\"   Cloning Arbor repository...\")\n",
    "            !git clone https://github.com/Noema-Research/Arbor.git arbor-o1-living-ai\n",
    "        \n",
    "        # Change to the repo directory and install\n",
    "        if os.path.exists(\"arbor-o1-living-ai\"):\n",
    "            print(\"   Installing from cloned repository...\")\n",
    "            !cd arbor-o1-living-ai && pip install -q -e .\n",
    "            print(\"âœ… Arbor installed from cloned repository!\")\n",
    "            arbor_installed = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Repository clone/install failed: {e}\")\n",
    "\n",
    "# Option 3: Check if we're already in the Arbor directory\n",
    "if not arbor_installed:\n",
    "    print(\"\\nğŸ“ Checking for local Arbor directory...\")\n",
    "    if Path(\"arbor\").exists() and Path(\"pyproject.toml\").exists():\n",
    "        print(\"   Found Arbor source - installing in development mode...\")\n",
    "        try:\n",
    "            !pip install -q -e .\n",
    "            print(\"âœ… Arbor installed in development mode!\")\n",
    "            arbor_installed = True\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Development installation failed: {e}\")\n",
    "\n",
    "# Option 4: Fallback - manual path setup\n",
    "if not arbor_installed:\n",
    "    print(\"\\nğŸ”§ Setting up manual path-based import...\")\n",
    "    import sys\n",
    "    \n",
    "    # Try multiple possible paths\n",
    "    possible_paths = [\n",
    "        \".\",\n",
    "        \"arbor-o1-living-ai\", \n",
    "        \"/content/arbor-o1-living-ai\",\n",
    "        str(Path.cwd())\n",
    "    ]\n",
    "    \n",
    "    for path in possible_paths:\n",
    "        if Path(path, \"arbor\").exists():\n",
    "            sys.path.insert(0, str(Path(path).absolute()))\n",
    "            print(f\"   Added {path} to Python path\")\n",
    "            break\n",
    "    \n",
    "    print(\"   ğŸ“ Note: Using path-based import - some features may be limited\")\n",
    "\n",
    "# Verify installations\n",
    "print(\"\\nğŸ” Verifying installations...\")\n",
    "\n",
    "# Check key packages\n",
    "key_packages = {\n",
    "    'torch': 'PyTorch',\n",
    "    'transformers': 'HuggingFace Transformers', \n",
    "    'datasets': 'HuggingFace Datasets',\n",
    "    'streamlit': 'Streamlit Dashboard',\n",
    "    'plotly': 'Plotly Visualization'\n",
    "}\n",
    "\n",
    "for package, name in key_packages.items():\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"   âœ… {name}\")\n",
    "    except ImportError:\n",
    "        print(f\"   âŒ {name} - installation may have failed\")\n",
    "\n",
    "# Special comprehensive check for Arbor\n",
    "print(f\"\\nğŸŒ± Checking Arbor installation...\")\n",
    "arbor_available = False\n",
    "\n",
    "try:\n",
    "    # First try direct import\n",
    "    import arbor\n",
    "    print(f\"   âœ… Arbor imported successfully (version: {getattr(arbor, '__version__', 'development')})\")\n",
    "    arbor_available = True\n",
    "except ImportError as e1:\n",
    "    print(f\"   âš ï¸ Direct import failed: {e1}\")\n",
    "    \n",
    "    # Try with path manipulation\n",
    "    import sys\n",
    "    paths_to_try = [\".\", \"arbor-o1-living-ai\", \"/content/arbor-o1-living-ai\"]\n",
    "    \n",
    "    for path in paths_to_try:\n",
    "        try:\n",
    "            if Path(path, \"arbor\").exists():\n",
    "                if str(Path(path).absolute()) not in sys.path:\n",
    "                    sys.path.insert(0, str(Path(path).absolute()))\n",
    "                import arbor\n",
    "                print(f\"   âœ… Arbor imported with path: {path}\")\n",
    "                arbor_available = True\n",
    "                break\n",
    "        except ImportError:\n",
    "            continue\n",
    "    \n",
    "    if not arbor_available:\n",
    "        print(f\"   âŒ Arbor not available - notebook will work with limited functionality\")\n",
    "\n",
    "print(\"\\nğŸ¯ Installation Summary:\")\n",
    "if arbor_available:\n",
    "    print(\"   â€¢ âœ… All systems ready - full functionality available!\")\n",
    "    print(\"   â€¢ âœ… Arbor package properly installed and importable\")\n",
    "else:\n",
    "    print(\"   â€¢ âš ï¸ Arbor not fully installed - some features may be limited\")\n",
    "    print(\"   â€¢ ğŸ“ Tutorial will continue with simulations where needed\")\n",
    "\n",
    "print(\"   â€¢ If you see any âŒ errors, try restarting runtime and re-running\")\n",
    "print(\"   â€¢ For Google Colab: Some packages may require runtime restart\")\n",
    "print(\"   â€¢ Cloud environments sometimes have installation restrictions\")\n",
    "\n",
    "print(\"\\nğŸš€ Ready to proceed with YAML training!\")\n",
    "\n",
    "# Environment-specific tips\n",
    "try:\n",
    "    import google.colab\n",
    "    print(\"\\nğŸ’¡ Google Colab Tips:\")\n",
    "    print(\"   â€¢ Repository cloned to: /content/arbor-o1-living-ai\")\n",
    "    print(\"   â€¢ Use 'Runtime â†’ Restart runtime' if you encounter import issues\")\n",
    "    print(\"   â€¢ Some packages may require runtime restart to work properly\")\n",
    "    print(\"   â€¢ The notebook is designed to work even with limited Arbor functionality\")\n",
    "    \n",
    "    # Show current working directory\n",
    "    import os\n",
    "    print(f\"   â€¢ Current directory: {os.getcwd()}\")\n",
    "    if os.path.exists(\"arbor-o1-living-ai\"):\n",
    "        print(\"   â€¢ âœ… Arbor repository is available\")\n",
    "    else:\n",
    "        print(\"   â€¢ âš ï¸ Arbor repository not found - some features may be limited\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"\\nğŸ’» Local Environment:\")\n",
    "    print(\"   â€¢ Make sure you're running from the arbor-o1-living-ai directory\")\n",
    "    print(\"   â€¢ Or the notebook will clone the repository automatically\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f566f747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Detection and Colab Setup\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Detect if we're running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"ğŸŒ Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"ğŸ’» Running locally\")\n",
    "\n",
    "# Setup for Google Colab\n",
    "if IN_COLAB:\n",
    "    print(\"ğŸ”§ Setting up Google Colab environment...\")\n",
    "    \n",
    "    # Install additional packages needed for Colab\n",
    "    print(\"ğŸ“¦ Installing required packages...\")\n",
    "    !pip install -q streamlit pyngrok plotly\n",
    "    \n",
    "    # Setup ngrok for public URL access\n",
    "    print(\"ğŸŒ Setting up public URL access with ngrok...\")\n",
    "    \n",
    "    # Import ngrok after installation\n",
    "    from pyngrok import ngrok\n",
    "    import getpass\n",
    "    \n",
    "    # Get ngrok auth token (user needs to provide this)\n",
    "    print(\"ğŸ”‘ To access the dashboard publicly, you need an ngrok auth token:\")\n",
    "    print(\"   1. Go to https://ngrok.com/ and sign up (free)\")\n",
    "    print(\"   2. Get your auth token from https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
    "    print(\"   3. Enter it below (or set NGROK_AUTH_TOKEN environment variable)\")\n",
    "    \n",
    "    ngrok_token = os.getenv('NGROK_AUTH_TOKEN')\n",
    "    if not ngrok_token:\n",
    "        print(\"ğŸ’¡ Tip: Set NGROK_AUTH_TOKEN environment variable to skip this step\")\n",
    "        # For now, we'll handle this when starting the dashboard\n",
    "        pass\n",
    "    else:\n",
    "        ngrok.set_auth_token(ngrok_token)\n",
    "        print(\"âœ… ngrok authentication configured\")\n",
    "    \n",
    "    # Set Colab-specific configurations\n",
    "    DASHBOARD_PORT = 8501\n",
    "    PUBLIC_URL = None  # Will be set when dashboard starts\n",
    "    \n",
    "else:\n",
    "    # Local development setup\n",
    "    DASHBOARD_PORT = 8501\n",
    "    LOCAL_URL = f\"http://localhost:{DASHBOARD_PORT}\"\n",
    "    print(f\"ğŸ  Local dashboard will be available at: {LOCAL_URL}\")\n",
    "\n",
    "print(\"âœ… Environment setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40776a90",
   "metadata": {},
   "source": [
    "## Step 1: Create Your Training Configuration\n",
    "\n",
    "The YAML trainer uses configuration files to specify everything about your training run. Let's start by examining and customizing a training configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a72895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the example configuration first\n",
    "config_path = Path(\"configs/example_config.yaml\")\n",
    "\n",
    "if config_path.exists():\n",
    "    with open(config_path, 'r') as f:\n",
    "        config_content = f.read()\n",
    "    \n",
    "    print(\"ğŸ“‹ Example Configuration Structure:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Show first 30 lines to get an overview\n",
    "    lines = config_content.split('\\n')\n",
    "    for i, line in enumerate(lines[:30]):\n",
    "        print(f\"{i+1:2d}: {line}\")\n",
    "    \n",
    "    if len(lines) > 30:\n",
    "        print(f\"... ({len(lines) - 30} more lines)\")\n",
    "else:\n",
    "    print(\"âŒ Example config not found. Let's create one!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15cdd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimized T4 GPU configuration for 1B model with all features\n",
    "print(\"ğŸš€ Creating T4-Optimized 1B Model Configuration\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "t4_optimized_config = {\n",
    "    'model': {\n",
    "        'name': 'arbor-1b-t4-demo',\n",
    "        'tokenizer_name': 'NousResearch/Hermes-3-Llama-3.1-8B',\n",
    "        'vocab_size': 128256,\n",
    "        \n",
    "        # 1B parameter architecture optimized for T4\n",
    "        'hidden_size': 2048,      # Good balance for T4 memory\n",
    "        'num_layers': 24,         # Starting layers (will grow to 32)\n",
    "        'num_heads': 16,          # 2048 / 16 = 128 head dim\n",
    "        'ffn_dim': 5504,          # ~2.7x hidden_size for efficiency\n",
    "        'max_seq_length': 4096,   # Good for most tasks\n",
    "        \n",
    "        # Layer Growth Configuration\n",
    "        'layer_growth': {\n",
    "            'enabled': True,\n",
    "            'min_layers': 24,\n",
    "            'max_layers': 32,           # Conservative for T4 memory\n",
    "            'growth_factor': 2,         # Add 2 layers at a time\n",
    "            'growth_threshold': 0.88,   # Trigger when 88% utilized\n",
    "            'growth_cooldown': 100,     # Wait 100 steps between growth\n",
    "            'utilization_window': 10    # Average over 10 steps\n",
    "        },\n",
    "        \n",
    "        # Parameter Growth Configuration  \n",
    "        'growth': {\n",
    "            'enabled': True,\n",
    "            'factor': 1.5,              # Moderate growth for stability\n",
    "            'threshold': 0.85,          # Conservative threshold\n",
    "            'max_steps': 3,             # Max 3 growth events\n",
    "            'cooldown': 75              # Wait between parameter growth\n",
    "        },\n",
    "        \n",
    "        # Adaptive Context (great for demos)\n",
    "        'adaptive_context': {\n",
    "            'enabled': True,\n",
    "            'min_context_length': 512,\n",
    "            'max_context_length': 4096,\n",
    "            'context_lengths': [512, 1024, 2048, 4096],\n",
    "            'task_types': ['chat', 'code', 'reasoning', 'document'],\n",
    "            'adaptation_threshold': 0.7\n",
    "        },\n",
    "        \n",
    "        # T4 Memory Optimizations\n",
    "        'use_cache': False,           # Save memory during training\n",
    "        'gradient_checkpointing': True,\n",
    "        'attention_dropout': 0.1,\n",
    "        'hidden_dropout': 0.1\n",
    "    },\n",
    "    \n",
    "    'datasets': [\n",
    "        {\n",
    "            'name': 'tinystories_demo',\n",
    "            'source': 'roneneldan/TinyStories',\n",
    "            'split': 'train[:5000]',    # Small for demo\n",
    "            'text_column': 'text',\n",
    "            'preprocessing': {\n",
    "                'prefix': 'ğŸ“š Story: ',\n",
    "                'suffix': ' [END]',\n",
    "                'max_length': 1024,     # Shorter for variety\n",
    "                'min_length': 100\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'name': 'code_demo',\n",
    "            'source': 'codeparrot/github-code-clean',\n",
    "            'split': 'train[:2000]',    # Small code samples\n",
    "            'text_column': 'code',\n",
    "            'preprocessing': {\n",
    "                'prefix': 'ğŸ’» Code:\\n',\n",
    "                'suffix': '\\n# End of code',\n",
    "                'max_length': 2048,     # Longer for code\n",
    "                'filter_languages': ['python', 'javascript']\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'name': 'reasoning_demo',\n",
    "            'source': 'microsoft/orca-math-word-problems-200k',\n",
    "            'split': 'train[:1000]',    # Math reasoning\n",
    "            'text_column': 'question',\n",
    "            'preprocessing': {\n",
    "                'prefix': 'ğŸ§  Problem: ',\n",
    "                'suffix': ' [SOLVE]',\n",
    "                'max_length': 1536\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \n",
    "    'training': {\n",
    "        'output_dir': './arbor-1b-t4-demo',\n",
    "        \n",
    "        # T4-Optimized Training Settings\n",
    "        'learning_rate': 2e-4,            # Good starting LR for 1B\n",
    "        'warmup_steps': 200,              # Gradual warmup\n",
    "        'steps_per_dataset': 500,         # 1500 total steps across 3 datasets\n",
    "        'max_train_steps': 1500,\n",
    "        \n",
    "        # T4 Memory Management\n",
    "        'per_device_train_batch_size': 1,  # Small batch for T4\n",
    "        'gradient_accumulation_steps': 16, # Effective batch size = 16\n",
    "        'dataloader_num_workers': 2,       # Don't overwhelm T4\n",
    "        \n",
    "        # Mixed Precision & Optimization\n",
    "        'fp16': True,                      # Essential for T4\n",
    "        'bf16': False,                     # T4 doesn't support bf16\n",
    "        'gradient_checkpointing': True,    # Save memory\n",
    "        'optim': 'adamw_torch',\n",
    "        'weight_decay': 0.01,\n",
    "        'adam_beta1': 0.9,\n",
    "        'adam_beta2': 0.999,\n",
    "        'adam_epsilon': 1e-8,\n",
    "        'max_grad_norm': 1.0,\n",
    "        \n",
    "        # Evaluation & Saving\n",
    "        'eval_steps': 100,                 # Frequent evaluation\n",
    "        'save_steps': 250,                 # Save checkpoints\n",
    "        'save_total_limit': 3,\n",
    "        'logging_steps': 25,               # Detailed logging\n",
    "        \n",
    "        # Efficiency Settings\n",
    "        'remove_unused_columns': True,\n",
    "        'prediction_loss_only': True,\n",
    "        'use_mps_device': False           # T4 is CUDA\n",
    "    },\n",
    "    \n",
    "    'logging': {\n",
    "        'arbor_tracking': {\n",
    "            'enabled': True,\n",
    "            'save_dir': './t4_training_logs',\n",
    "            'update_interval': 0.5,        # Frequent updates for demo\n",
    "            'dashboard_port': 8502,        # Different port for demo\n",
    "            'alerts': {\n",
    "                'enabled': True,\n",
    "                'email_notifications': False,\n",
    "                'webhook_url': None,\n",
    "                'alert_thresholds': {\n",
    "                    'loss_spike': 2.0,     # Alert if loss > 2x avg\n",
    "                    'memory_usage': 0.9,   # Alert at 90% memory\n",
    "                    'gradient_norm': 10.0, # Alert for gradient explosion\n",
    "                    'learning_rate_drop': 0.5  # Alert for LR scheduler issues\n",
    "                }\n",
    "            },\n",
    "            'metrics': {\n",
    "                'track_gpu_memory': True,\n",
    "                'track_layer_utilization': True,\n",
    "                'track_gradient_norms': True,\n",
    "                'track_learning_rates': True,\n",
    "                'export_frequency': 'every_100_steps'\n",
    "            }\n",
    "        },\n",
    "        'console': {\n",
    "            'enabled': True,\n",
    "            'level': 'INFO',\n",
    "            'format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "        },\n",
    "        'tensorboard': {\n",
    "            'enabled': True,\n",
    "            'log_dir': './t4_tensorboard_logs'\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'huggingface': {\n",
    "        'upload': {\n",
    "            'enabled': False,              # Can enable for demo\n",
    "            'repository': 'your-username/arbor-1b-t4-demo',\n",
    "            'private': False,\n",
    "            'push_to_hub_frequency': 500\n",
    "        },\n",
    "        'token': None  # Set your HF token if uploading\n",
    "    },\n",
    "    \n",
    "    # Demo-specific features\n",
    "    'demo_features': {\n",
    "        'enable_growth_visualization': True,\n",
    "        'save_architecture_snapshots': True,\n",
    "        'generate_sample_outputs': True,\n",
    "        'create_training_video': False,    # Set True for video generation\n",
    "        'benchmark_performance': True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the T4-optimized configuration\n",
    "t4_config_path = Path(\"configs/t4_1b_demo_config.yaml\")\n",
    "t4_config_path.parent.mkdir(exist_ok=True)\n",
    "\n",
    "with open(t4_config_path, 'w') as f:\n",
    "    yaml.dump(t4_optimized_config, f, default_flow_style=False, indent=2)\n",
    "\n",
    "print(\"âœ… Created T4-optimized 1B model configuration!\")\n",
    "print(f\"ğŸ“ Saved to: {t4_config_path}\")\n",
    "print(\"\\nğŸ¯ Configuration Highlights:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ğŸ“Š Model: ~1B parameters (2048 hidden, 24â†’32 layers)\")\n",
    "print(f\"ğŸ§  Memory: Optimized for T4 GPU (16GB)\")\n",
    "print(f\"ğŸŒ± Growth: Layer growth (24â†’32) + parameter growth\")\n",
    "print(f\"ğŸ“ˆ Dashboard: Enhanced tracking at http://localhost:8502\")\n",
    "print(f\"âš¡ Training: 1500 steps across 3 diverse datasets\")\n",
    "print(f\"ğŸ”„ Context: Adaptive 512â†’4096 tokens\")\n",
    "print(f\"ğŸ’¾ Batch: Effective size 16 (1Ã—16 accumulation)\")\n",
    "print(f\"ğŸ¯ Features: All demo features enabled\")\n",
    "\n",
    "print(\"\\nğŸ’¡ T4 Optimizations:\")\n",
    "print(\"  â€¢ FP16 precision for memory efficiency\")\n",
    "print(\"  â€¢ Gradient checkpointing enabled\")\n",
    "print(\"  â€¢ Small batch size with accumulation\")\n",
    "print(\"  â€¢ Conservative growth thresholds\")\n",
    "print(\"  â€¢ Frequent logging for monitoring\")\n",
    "\n",
    "print(\"\\nğŸš€ Perfect for:\")\n",
    "print(\"  â€¢ Live training demonstrations\")\n",
    "print(\"  â€¢ Growth visualization\")\n",
    "print(\"  â€¢ Real-time dashboard monitoring\")\n",
    "print(\"  â€¢ T4/Colab compatibility\")\n",
    "print(\"  â€¢ Educational showcases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beccf7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to use the T4-optimized configuration\n",
    "print(\"ğŸ® How to Use the T4 Configuration\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"1. ğŸš€ Quick Start (Local with T4):\")\n",
    "print(\"   python train.py configs/t4_1b_demo_config.yaml\")\n",
    "print()\n",
    "\n",
    "print(\"2. ğŸ“Š With Dashboard (Recommended):\")\n",
    "print(\"   # Terminal 1: Start dashboard\")\n",
    "print(\"   streamlit run arbor/tracking/dashboard.py --server.port=8502\")\n",
    "print(\"   # Terminal 2: Start training\")  \n",
    "print(\"   python train.py configs/t4_1b_demo_config.yaml\")\n",
    "print(\"   # View at: http://localhost:8502\")\n",
    "print()\n",
    "\n",
    "print(\"3. ğŸŒ Google Colab with T4:\")\n",
    "print(\"   # Enable T4 GPU: Runtime â†’ Change runtime type â†’ T4 GPU\")\n",
    "print(\"   # Run the Colab setup cells above\")\n",
    "print(\"   # Use this config with the dashboard!\")\n",
    "print()\n",
    "\n",
    "print(\"4. ğŸ“ˆ What You'll See:\")\n",
    "print(\"   â€¢ Real-time loss curves across 3 different datasets\")\n",
    "print(\"   â€¢ Layer growth from 24 â†’ 32 layers during training\")\n",
    "print(\"   â€¢ Parameter growth events (FFN expansion)\")\n",
    "print(\"   â€¢ Adaptive context switching between task types\")\n",
    "print(\"   â€¢ GPU memory utilization tracking\")\n",
    "print(\"   â€¢ Growth event alerts and notifications\")\n",
    "print()\n",
    "\n",
    "print(\"5. ğŸ’¾ Expected Training Time:\")\n",
    "print(\"   â€¢ T4 GPU: ~45-60 minutes for full 1500 steps\")\n",
    "print(\"   â€¢ Checkpoints saved every 250 steps\")\n",
    "print(\"   â€¢ Dashboard updates every 0.5 seconds\")\n",
    "print(\"   â€¢ Growth events typically occur around steps 400, 800, 1200\")\n",
    "print()\n",
    "\n",
    "print(\"6. ğŸ¯ Demo Scenarios:\")\n",
    "print(\"   â€¢ Show adaptive context: Watch context length change by dataset\")\n",
    "print(\"   â€¢ Demonstrate growth: Model architecture evolves during training\")\n",
    "print(\"   â€¢ Monitor performance: Real-time GPU utilization and efficiency\")\n",
    "print(\"   â€¢ Alert system: Get notified of training events\")\n",
    "print()\n",
    "\n",
    "# Memory estimation\n",
    "print(\"ğŸ’¾ Memory Requirements:\")\n",
    "print(\"=\" * 25)\n",
    "model_params = 1.0  # 1B parameters\n",
    "bytes_per_param = 4  # FP32\n",
    "fp16_savings = 0.5   # FP16 uses half memory\n",
    "gradient_multiplier = 2  # Gradients + optimizer states\n",
    "activation_memory = 2    # Activation memory (GB)\n",
    "\n",
    "base_memory = model_params * bytes_per_param * fp16_savings * gradient_multiplier\n",
    "total_memory = base_memory + activation_memory\n",
    "\n",
    "print(f\"Model parameters: {model_params:.1f}B\")\n",
    "print(f\"Base memory (FP16): {base_memory:.1f}GB\")\n",
    "print(f\"Activation memory: {activation_memory:.1f}GB\")\n",
    "print(f\"Total estimated: {total_memory:.1f}GB\")\n",
    "print(f\"T4 GPU memory: 16GB\")\n",
    "print(f\"Memory utilization: {(total_memory/16)*100:.1f}%\")\n",
    "print(\"âœ… Fits comfortably on T4!\")\n",
    "\n",
    "print(f\"\\nğŸ”§ To customize this config:\")\n",
    "print(f\"   â€¢ Edit configs/t4_1b_demo_config.yaml\")\n",
    "print(f\"   â€¢ Adjust batch_size/accumulation for your GPU\")\n",
    "print(f\"   â€¢ Change growth thresholds for more/less growth\")\n",
    "print(f\"   â€¢ Add your own datasets\")\n",
    "print(f\"   â€¢ Configure alerts and notifications\")\n",
    "\n",
    "# Set this as the active tutorial config\n",
    "tutorial_config = t4_optimized_config\n",
    "tutorial_config_path = t4_config_path\n",
    "\n",
    "print(f\"\\nâœ… T4 config is now active for the rest of this tutorial!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b177fc01",
   "metadata": {},
   "source": [
    "## Step 2: Understanding the YAML Configuration\n",
    "\n",
    "Let's examine the key sections of our configuration and what they control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5657bc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore each section of our configuration\n",
    "print(\"ğŸ” Configuration Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Model configuration\n",
    "model_config = tutorial_config['model']\n",
    "print(\"\\nğŸ¤– MODEL CONFIGURATION:\")\n",
    "print(f\"   Vocabulary: {model_config['vocab_size']:,} tokens (Hermes-4-405B)\")\n",
    "print(f\"   Architecture: {model_config['num_layers']} layers Ã— {model_config['hidden_size']} dim\")\n",
    "print(f\"   Parameters: ~{(model_config['hidden_size'] * model_config['num_layers'] * 4) / 1e6:.0f}M\")\n",
    "\n",
    "# Growth settings\n",
    "growth = model_config['growth']\n",
    "print(f\"\\nğŸŒ± GROWTH SETTINGS:\")\n",
    "print(f\"   Enabled: {growth['enabled']}\")\n",
    "print(f\"   Growth factor: {growth['factor']}x\")\n",
    "print(f\"   Max growth steps: {growth['max_steps']}\")\n",
    "print(f\"   Trigger threshold: {growth['threshold']}\")\n",
    "\n",
    "# Adaptive context\n",
    "adaptive = model_config['adaptive_context']\n",
    "print(f\"\\nğŸ§  ADAPTIVE CONTEXT:\")\n",
    "print(f\"   Enabled: {adaptive['enabled']}\")\n",
    "print(f\"   Context range: {adaptive['min_context_length']:,} - {adaptive['max_context_length']:,}\")\n",
    "print(f\"   Task types: {len(adaptive['task_types'])} ({', '.join(adaptive['task_types'])})\")\n",
    "print(f\"   Context options: {len(adaptive['context_lengths'])} levels\")\n",
    "\n",
    "# Datasets\n",
    "datasets = tutorial_config['datasets']\n",
    "print(f\"\\nğŸ“š DATASETS:\")\n",
    "for i, dataset in enumerate(datasets, 1):\n",
    "    print(f\"   {i}. {dataset['name']}: {dataset['source']} ({dataset['split']})\")\n",
    "    print(f\"      Max length: {dataset['preprocessing']['max_length']} tokens\")\n",
    "\n",
    "# Tracking and logging\n",
    "logging_config = tutorial_config['logging']\n",
    "print(f\"\\nğŸ“Š ARBOR TRACKING & LOGGING:\")\n",
    "arbor_tracking = logging_config['arbor_tracking']\n",
    "print(f\"   Dashboard enabled: {arbor_tracking['enabled']}\")\n",
    "print(f\"   Save directory: {arbor_tracking['save_dir']}\")\n",
    "print(f\"   Dashboard port: {arbor_tracking['dashboard_port']}\")\n",
    "print(f\"   Live monitoring: {arbor_tracking['update_interval']}s intervals\")\n",
    "print(f\"   Alerts enabled: {arbor_tracking['alerts']['enabled']}\")\n",
    "print(f\"   Console logging: {logging_config['console']['enabled']} ({logging_config['console']['level']})\")\n",
    "\n",
    "# Training\n",
    "training = tutorial_config['training']\n",
    "print(f\"\\nğŸ¯ TRAINING:\")\n",
    "print(f\"   Learning rate: {training['learning_rate']}\")\n",
    "print(f\"   Batch size: {training['per_device_train_batch_size']} Ã— {training['gradient_accumulation_steps']} = {training['per_device_train_batch_size'] * training['gradient_accumulation_steps']}\")\n",
    "print(f\"   Total steps: {len(datasets)} Ã— {training['steps_per_dataset']} = {len(datasets) * training['steps_per_dataset']}\")\n",
    "print(f\"   Mixed precision: {training['fp16']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c365cf",
   "metadata": {},
   "source": [
    "## Step 3: Initialize the YAML Trainer\n",
    "\n",
    "Now let's create and initialize the YAML trainer with our configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eaed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the YAML trainer\n",
    "try:\n",
    "    from arbor.train.yaml_trainer import ArborYAMLTrainer\n",
    "    print(\"âœ… Successfully imported ArborYAMLTrainer\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")\n",
    "    print(\"Make sure you're in the correct directory and arbor is in the path\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b52b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the trainer\n",
    "print(\"ğŸš€ Initializing YAML Trainer...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    trainer = ArborYAMLTrainer(str(tutorial_config_path))\n",
    "    print(\"âœ… Trainer initialized successfully!\")\n",
    "    \n",
    "    # The trainer automatically validates the configuration\n",
    "    print(\"\\nğŸ“‹ Configuration loaded and validated\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Trainer initialization failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6da191e",
   "metadata": {},
   "source": [
    "## Step 4: Setup Components\n",
    "\n",
    "The trainer needs to setup several components before training. Let's do this step by step to see what's happening:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a464b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4a: Setup tokenizer\n",
    "print(\"ğŸ“¥ Setting up tokenizer...\")\n",
    "try:\n",
    "    trainer.setup_tokenizer()\n",
    "    print(f\"âœ… Tokenizer ready: {len(trainer.tokenizer):,} vocabulary\")\n",
    "    \n",
    "    # Test the tokenizer\n",
    "    test_text = \"Hello, this is a test of the Hermes tokenizer!\"\n",
    "    tokens = trainer.tokenizer.encode(test_text)\n",
    "    print(f\"ğŸ§ª Test encoding: '{test_text}' â†’ {len(tokens)} tokens\")\n",
    "    print(f\"   First 10 tokens: {tokens[:10]}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Tokenizer setup failed: {e}\")\n",
    "    print(\"This might be due to internet connectivity or HuggingFace access\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20447431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4b: Setup model\n",
    "print(\"\\nğŸ¤– Setting up Arbor model...\")\n",
    "try:\n",
    "    trainer.setup_model()\n",
    "    print(f\"âœ… Model created: {trainer.model.param_count():,} parameters\")\n",
    "    \n",
    "    # Show model architecture details\n",
    "    config = trainer.model.config\n",
    "    print(f\"\\nğŸ“Š Model details:\")\n",
    "    print(f\"   Architecture: {config.num_layers} layers\")\n",
    "    print(f\"   Hidden size: {config.dim}\")\n",
    "    print(f\"   Attention heads: {config.num_heads}\")\n",
    "    print(f\"   FFN dimension: {config.ffn_dim}\")\n",
    "    print(f\"   Max sequence length: {config.max_seq_length:,}\")\n",
    "    \n",
    "    # Show adaptive context info\n",
    "    if hasattr(trainer.model, 'get_context_info'):\n",
    "        context_info = trainer.model.get_context_info()\n",
    "        print(f\"\\nğŸ§  Adaptive context info:\")\n",
    "        print(f\"   Enabled: {context_info['adaptive_context_enabled']}\")\n",
    "        if context_info['adaptive_context_enabled']:\n",
    "            print(f\"   Current context: {context_info['current_context_length']:,}\")\n",
    "            print(f\"   Context range: {context_info['min_context_length']:,} - {context_info['max_context_length']:,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Model setup failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab6fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4c: Load datasets\n",
    "print(\"\\nğŸ“š Loading datasets...\")\n",
    "try:\n",
    "    trainer.load_datasets()\n",
    "    \n",
    "    print(f\"âœ… Datasets loaded: {len(trainer.datasets)}\")\n",
    "    \n",
    "    # Show dataset info\n",
    "    for name, dataset in trainer.datasets.items():\n",
    "        print(f\"\\nğŸ“Š Dataset: {name}\")\n",
    "        print(f\"   Size: {len(dataset):,} examples\")\n",
    "        \n",
    "        # Show a sample\n",
    "        if len(dataset) > 0:\n",
    "            sample = dataset[0]\n",
    "            input_ids = sample['input_ids']\n",
    "            decoded = trainer.tokenizer.decode(input_ids[:50])  # First 50 tokens\n",
    "            print(f\"   Sample: {decoded}...\")\n",
    "            print(f\"   Token length: {len(input_ids)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Dataset loading failed: {e}\")\n",
    "    print(\"This might be due to internet connectivity or dataset access issues\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c539c8f4",
   "metadata": {},
   "source": [
    "## Step 5: Training Setup\n",
    "\n",
    "Before we start training, let's setup logging and create the trainer objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22b9c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Arbor tracking and logging\n",
    "print(\"ğŸ“Š Setting up Arbor tracking system...\")\n",
    "try:\n",
    "    # Initialize TrainingMonitor with configuration\n",
    "    tracking_config = tutorial_config['logging']['arbor_tracking']\n",
    "    \n",
    "    # Create training monitor\n",
    "    training_monitor = TrainingMonitor(\n",
    "        save_dir=tracking_config['save_dir'],\n",
    "        update_interval=tracking_config['update_interval']\n",
    "    )\n",
    "    \n",
    "    # Setup alert system if enabled\n",
    "    if tracking_config['alerts']['enabled']:\n",
    "        training_monitor.setup_alerts(\n",
    "            email_enabled=tracking_config['alerts']['email_notifications'],\n",
    "            webhook_url=tracking_config['alerts']['webhook_url']\n",
    "        )\n",
    "    \n",
    "    print(\"âœ… Arbor tracking system initialized\")\n",
    "    print(f\"   ğŸ“Š Dashboard will be available at: http://localhost:{tracking_config['dashboard_port']}\")\n",
    "    print(f\"   ğŸ’¾ Metrics saved to: {tracking_config['save_dir']}\")\n",
    "    print(f\"   ğŸ”” Alerts enabled: {tracking_config['alerts']['enabled']}\")\n",
    "    \n",
    "    # Setup traditional logging as well\n",
    "    trainer.setup_logging()\n",
    "    print(\"âœ… Console logging configured\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Tracking setup had issues: {e}\")\n",
    "    print(\"Training can continue with basic logging\")\n",
    "    # Fallback to basic logging\n",
    "    try:\n",
    "        trainer.setup_logging()\n",
    "        print(\"âœ… Basic logging configured\")\n",
    "    except:\n",
    "        print(\"âš ï¸ Even basic logging had issues - continuing anyway\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e02f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the Arbor Dashboard\n",
    "print(\"\\nğŸŒ Starting Arbor Dashboard...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "dashboard_port = tutorial_config['logging']['arbor_tracking']['dashboard_port']\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"ğŸŒ Google Colab Setup:\")\n",
    "    print(\"=\" * 30)\n",
    "    print(\"To access the dashboard in Colab, we'll create a public URL using ngrok.\")\n",
    "    print(\"\")\n",
    "    print(\"ğŸ“‹ Steps to access the dashboard:\")\n",
    "    print(\"1. ğŸ”‘ Get an ngrok token from https://ngrok.com (free signup)\")\n",
    "    print(\"2. ğŸš€ Run the dashboard startup cell below\")\n",
    "    print(\"3. ğŸŒ Click the public ngrok URL to access the dashboard\")\n",
    "    print(\"\")\n",
    "    print(\"ğŸ’¡ The dashboard will show:\")\n",
    "    print(\"   â€¢ ğŸ“ˆ Live training metrics (loss, learning rate)\")\n",
    "    print(\"   â€¢ ğŸ—ï¸ Model architecture with layer utilization\")  \n",
    "    print(\"   â€¢ ğŸŒ± Growth tracking (parameters and layers)\")\n",
    "    print(\"   â€¢ ğŸ”” Training alerts and notifications\")\n",
    "    print(\"   â€¢ ğŸ“Š Performance analytics and system monitoring\")\n",
    "    print(\"\")\n",
    "    print(\"âš ï¸ Note: In Colab, the dashboard will be accessible via a public ngrok URL\")\n",
    "    print(\"        Anyone with the URL can access it (ngrok free tier limitation)\")\n",
    "else:\n",
    "    print(\"ğŸ’» Local Development Setup:\")\n",
    "    print(\"=\" * 30)\n",
    "    print(\"To monitor training locally:\")\n",
    "    print(\"1. ğŸš€ Option A - Use the launcher:\")\n",
    "    print(\"   python launch_training_dashboard.py\")\n",
    "    print()\n",
    "    print(\"2. ğŸ“Š Option B - Start dashboard manually:\")\n",
    "    print(f\"   streamlit run arbor/tracking/dashboard.py --server.port={dashboard_port}\")\n",
    "    print()\n",
    "    print(\"3. ğŸŒ Then open your browser to:\")\n",
    "    print(f\"   http://localhost:{dashboard_port}\")\n",
    "\n",
    "print()\n",
    "print(\"ğŸ“Š Dashboard Features:\")\n",
    "print(\"   â€¢ ğŸ“ˆ Live training metrics with real-time updates\")\n",
    "print(\"   â€¢ ğŸ—ï¸ Interactive model architecture visualization\")\n",
    "print(\"   â€¢ ğŸŒ± Parameter and layer growth timeline\")\n",
    "print(\"   â€¢ ğŸ”” Alert system with configurable notifications\")\n",
    "print(\"   â€¢ ğŸ“Š Performance analytics and export capabilities\")\n",
    "print()\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"ğŸ”§ Next: Run the 'Start Dashboard in Colab' cell below to get your public URL!\")\n",
    "else:\n",
    "    print(\"ğŸ’¡ Tip: Start the dashboard in another terminal before running training!\")\n",
    "    print(\"    The dashboard will automatically pick up training data as it's generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78deb0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Dashboard in Colab (with public URL)\n",
    "if IN_COLAB:\n",
    "    print(\"ğŸš€ Starting Arbor Dashboard in Google Colab\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check if ngrok auth token is available\n",
    "    ngrok_token = os.getenv('NGROK_AUTH_TOKEN')\n",
    "    if not ngrok_token:\n",
    "        print(\"ğŸ”‘ Please enter your ngrok auth token:\")\n",
    "        print(\"   Get it from: https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
    "        ngrok_token = getpass.getpass(\"Enter ngrok auth token: \")\n",
    "        \n",
    "        if ngrok_token.strip():\n",
    "            ngrok.set_auth_token(ngrok_token.strip())\n",
    "            print(\"âœ… ngrok authentication configured\")\n",
    "        else:\n",
    "            print(\"âŒ No token provided - dashboard will only be accessible locally\")\n",
    "            print(\"   You can still run the dashboard, but won't get a public URL\")\n",
    "    \n",
    "    # Start the dashboard with threading to run in background\n",
    "    import threading\n",
    "    import subprocess\n",
    "    import time\n",
    "    \n",
    "    # Create a function to run streamlit\n",
    "    def run_streamlit():\n",
    "        try:\n",
    "            # Change to the correct directory and run streamlit\n",
    "            dashboard_cmd = [\n",
    "                sys.executable, \"-m\", \"streamlit\", \"run\", \n",
    "                \"arbor/tracking/dashboard.py\",\n",
    "                \"--server.port\", str(DASHBOARD_PORT),\n",
    "                \"--server.headless\", \"true\",\n",
    "                \"--server.enableCORS\", \"false\",\n",
    "                \"--browser.gatherUsageStats\", \"false\"\n",
    "            ]\n",
    "            \n",
    "            print(f\"ğŸ¬ Starting Streamlit dashboard...\")\n",
    "            subprocess.run(dashboard_cmd)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to start dashboard: {e}\")\n",
    "    \n",
    "    # Start streamlit in background thread\n",
    "    dashboard_thread = threading.Thread(target=run_streamlit, daemon=True)\n",
    "    dashboard_thread.start()\n",
    "    \n",
    "    # Wait a moment for streamlit to start\n",
    "    print(\"â³ Waiting for dashboard to initialize...\")\n",
    "    time.sleep(10)\n",
    "    \n",
    "    # Create ngrok tunnel if token is available\n",
    "    if ngrok_token and ngrok_token.strip():\n",
    "        try:\n",
    "            print(\"ğŸŒ Creating public tunnel with ngrok...\")\n",
    "            public_url = ngrok.connect(DASHBOARD_PORT)\n",
    "            PUBLIC_URL = public_url\n",
    "            \n",
    "            print(\"ğŸ‰ Dashboard is ready!\")\n",
    "            print(\"=\" * 50)\n",
    "            print(f\"ğŸŒ Public URL: {public_url}\")\n",
    "            print(f\"ğŸ“± Mobile-friendly: {public_url}\")\n",
    "            print(\"ğŸ”— Click the link above to access your dashboard\")\n",
    "            print()\n",
    "            print(\"âš ï¸ Security Note: This URL is public and accessible to anyone\")\n",
    "            print(\"   Consider using ngrok's paid plan for password protection\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to create ngrok tunnel: {e}\")\n",
    "            print(f\"ğŸ  Dashboard available locally at: http://localhost:{DASHBOARD_PORT}\")\n",
    "            print(\"   (Not accessible outside Colab without tunnel)\")\n",
    "    else:\n",
    "        print(f\"ğŸ  Dashboard running locally at: http://localhost:{DASHBOARD_PORT}\")\n",
    "        print(\"   (Not accessible outside Colab - need ngrok token for public access)\")\n",
    "\n",
    "else:\n",
    "    print(\"ğŸ’» Local Environment: Use the previous instructions to start the dashboard manually\")\n",
    "    print(\"    This cell is only for Google Colab automatic setup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e943737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a trainer for the first dataset to inspect the setup\n",
    "if trainer.datasets:\n",
    "    dataset_name = list(trainer.datasets.keys())[0]\n",
    "    print(f\"ğŸ”§ Creating trainer for dataset: {dataset_name}\")\n",
    "    \n",
    "    try:\n",
    "        hf_trainer = trainer.create_trainer(dataset_name)\n",
    "        print(f\"âœ… HuggingFace trainer created\")\n",
    "        print(f\"   Training dataset: {len(hf_trainer.train_dataset):,} examples\")\n",
    "        if hf_trainer.eval_dataset:\n",
    "            print(f\"   Eval dataset: {len(hf_trainer.eval_dataset):,} examples\")\n",
    "        \n",
    "        # Show training arguments\n",
    "        args = hf_trainer.args\n",
    "        print(f\"\\nâš™ï¸  Training arguments:\")\n",
    "        print(f\"   Output dir: {args.output_dir}\")\n",
    "        print(f\"   Learning rate: {args.learning_rate}\")\n",
    "        print(f\"   Batch size: {args.per_device_train_batch_size}\")\n",
    "        print(f\"   Max steps: {args.max_steps}\")\n",
    "        print(f\"   Save steps: {args.save_steps}\")\n",
    "        print(f\"   Eval steps: {args.eval_steps}\")\n",
    "        print(f\"   FP16: {args.fp16}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Trainer creation failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8374699f",
   "metadata": {},
   "source": [
    "## Step 6: Test Adaptive Context System\n",
    "\n",
    "Before training, let's test the adaptive context system with different types of inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febb0659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the adaptive context system\n",
    "print(\"ğŸ§  Testing Adaptive Context System\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test different types of inputs\n",
    "test_inputs = {\n",
    "    \"simple_chat\": \"Hello! How are you today?\",\n",
    "    \n",
    "    \"code_task\": \"\"\"\n",
    "def fibonacci(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    else:\n",
    "        return fibonacci(n-1) + fibonacci(n-2)\n",
    "\n",
    "# This is a recursive implementation\n",
    "# Could be optimized with dynamic programming\n",
    "for i in range(10):\n",
    "    print(f\"fib({i}) = {fibonacci(i)}\")\n",
    "\"\"\",\n",
    "    \n",
    "    \"reasoning_task\": \"\"\"\n",
    "Let me think through this step by step. If we have a logical puzzle where:\n",
    "1. All cats are animals\n",
    "2. Some animals are pets  \n",
    "3. No pets are wild\n",
    "4. Some cats are wild\n",
    "\n",
    "We need to determine if there's a contradiction. Let me analyze each statement carefully\n",
    "and see if they can all be true simultaneously. This requires careful logical reasoning\n",
    "to avoid making invalid inferences.\n",
    "\"\"\",\n",
    "    \n",
    "    \"long_document\": \"\"\"\n",
    "This is a comprehensive research paper on machine learning that covers multiple aspects\n",
    "of the field. The introduction provides background on artificial intelligence and its\n",
    "historical development. The methodology section describes various approaches including\n",
    "supervised learning, unsupervised learning, and reinforcement learning paradigms.\n",
    "\"\"\" + \" The paper continues with detailed analysis.\" * 50  # Make it longer\n",
    "}\n",
    "\n",
    "# Test each input type\n",
    "for task_type, text in test_inputs.items():\n",
    "    print(f\"\\nğŸ” Testing: {task_type}\")\n",
    "    print(f\"Input length: {len(text)} characters\")\n",
    "    \n",
    "    # Tokenize the input\n",
    "    inputs = trainer.tokenizer(text, return_tensors=\"pt\", truncation=False)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    token_count = input_ids.shape[1]\n",
    "    print(f\"Token count: {token_count}\")\n",
    "    \n",
    "    # Get current context info\n",
    "    initial_context = trainer.model.get_context_info()['current_context_length']\n",
    "    \n",
    "    # Test the model (this should trigger adaptive context)\n",
    "    trainer.model.eval()\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            # This forward pass will trigger context adaptation\n",
    "            outputs = trainer.model(input_ids, return_dict=True)\n",
    "            \n",
    "            # Check if context adapted\n",
    "            final_context = trainer.model.get_context_info()['current_context_length']\n",
    "            \n",
    "            print(f\"Context: {initial_context:,} â†’ {final_context:,} tokens\")\n",
    "            if final_context != initial_context:\n",
    "                print(f\"âœ… Context adapted for {task_type}\")\n",
    "            else:\n",
    "                print(f\"â†’ Context unchanged for {task_type}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error processing {task_type}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc04629",
   "metadata": {},
   "source": [
    "## Step 7: Run Training\n",
    "\n",
    "Now let's run the actual training! We'll train for a short period to demonstrate the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33735d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: This will actually train the model!\n",
    "print(\"âš ï¸  TRAINING WARNING\")\n",
    "print(\"=\" * 50)\n",
    "print(\"The next cell will run actual training.\")\n",
    "print(\"This may take several minutes and will:\")\n",
    "print(\"â€¢ Download datasets from HuggingFace\")\n",
    "print(\"â€¢ Train the model for 200 steps\")\n",
    "print(\"â€¢ Show parameter growth during training\")\n",
    "print(\"â€¢ Save model checkpoints\")\n",
    "print(\"\")\n",
    "print(\"Set RUN_TRAINING = True to proceed\")\n",
    "\n",
    "RUN_TRAINING = False  # Set to True to actually run training\n",
    "\n",
    "if RUN_TRAINING:\n",
    "    print(\"ğŸš€ Starting training pipeline...\")\n",
    "else:\n",
    "    print(\"ğŸ›‘ Training skipped (set RUN_TRAINING = True to run)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17ef955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training if enabled\n",
    "if RUN_TRAINING:\n",
    "    print(\"ğŸš€ Starting Arbor YAML Training Pipeline with Live Dashboard\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Start monitoring\n",
    "        if 'training_monitor' in locals():\n",
    "            training_monitor.start_monitoring()\n",
    "            print(\"ğŸ“Š Training monitor started - metrics will be saved for dashboard\")\n",
    "        \n",
    "        # Show dashboard access info\n",
    "        if IN_COLAB and 'PUBLIC_URL' in globals() and PUBLIC_URL:\n",
    "            print(f\"ğŸŒ Monitor training at: {PUBLIC_URL}\")\n",
    "        elif not IN_COLAB:\n",
    "            dashboard_port = tutorial_config['logging']['arbor_tracking']['dashboard_port']\n",
    "            print(f\"ğŸŒ Monitor training at: http://localhost:{dashboard_port}\")\n",
    "        else:\n",
    "            print(\"ğŸ“Š Dashboard metrics being collected (check dashboard startup cells for URL)\")\n",
    "        \n",
    "        # This runs the complete training pipeline\n",
    "        trainer.train()\n",
    "        \n",
    "        print(\"\\nğŸ‰ Training completed successfully!\")\n",
    "        \n",
    "        # Show final model stats\n",
    "        final_params = trainer.model.param_count()\n",
    "        print(f\"ğŸ“Š Final model size: {final_params:,} parameters\")\n",
    "        \n",
    "        # Show training outputs\n",
    "        output_dir = Path(trainer.config.training_config['output_dir'])\n",
    "        if output_dir.exists():\n",
    "            saved_models = list(output_dir.glob(\"*/\"))\n",
    "            print(f\"ğŸ’¾ Saved {len(saved_models)} model checkpoints:\")\n",
    "            for model_dir in saved_models:\n",
    "                print(f\"   ğŸ“ {model_dir.name}\")\n",
    "        \n",
    "        # Stop monitoring and generate report\n",
    "        if 'training_monitor' in locals():\n",
    "            training_monitor.stop_monitoring()\n",
    "            report_file = training_monitor.export_training_report()\n",
    "            print(f\"ğŸ“„ Training report saved: {report_file}\")\n",
    "            \n",
    "            # Show final dashboard link\n",
    "            if IN_COLAB and 'PUBLIC_URL' in globals() and PUBLIC_URL:\n",
    "                print(f\"\\nğŸŒ View final metrics at: {PUBLIC_URL}\")\n",
    "            elif not IN_COLAB:\n",
    "                dashboard_port = tutorial_config['logging']['arbor_tracking']['dashboard_port']\n",
    "                print(f\"\\nğŸŒ View final metrics at: http://localhost:{dashboard_port}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Training failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        # Stop monitoring on error\n",
    "        if 'training_monitor' in locals():\n",
    "            training_monitor.stop_monitoring()\n",
    "        \n",
    "else:\n",
    "    # Simulate what training would show with Arbor tracking\n",
    "    print(\"ğŸ“‹ Training simulation (would show):\")\n",
    "    print(\"ğŸŒ± Initialized Arbor trainer with config: configs/tutorial_config.yaml\")\n",
    "    print(\"ğŸ“Š Arbor tracking system initialized:\")\n",
    "    \n",
    "    if IN_COLAB:\n",
    "        print(\"   â€¢ Dashboard ready with public ngrok URL\")\n",
    "        if 'PUBLIC_URL' in globals() and PUBLIC_URL:\n",
    "            print(f\"   â€¢ Access at: {PUBLIC_URL}\")\n",
    "        else:\n",
    "            print(\"   â€¢ Public URL will be generated when dashboard starts\")\n",
    "    else:\n",
    "        print(\"   â€¢ Dashboard ready at http://localhost:8501\")\n",
    "    \n",
    "    print(\"   â€¢ Metrics saved to: ./training_logs\")\n",
    "    print(\"   â€¢ Real-time monitoring enabled\")\n",
    "    print(\"   â€¢ Alert system active\")\n",
    "    print(\" Downloading fresh Hermes-4-405B tokenizer...\")\n",
    "    print(\"âœ… Successfully loaded fresh Hermes-4-405B tokenizer\")\n",
    "    print(\"âœ… Created Arbor model: 347,394,048 parameters\")\n",
    "    print(\"ğŸ§  Adaptive context enabled:\")\n",
    "    print(\"   Range: 512 - 32,768\")\n",
    "    print(\"   Supported tasks: 4\")\n",
    "    print(\"ğŸŒ± Growth monitoring enabled:\")\n",
    "    print(\"   Factor: 1.5x\")\n",
    "    print(\"   Max steps: 4\")\n",
    "    print(\"ğŸ“š Loading datasets...\")\n",
    "    print(\"   âœ… tiny_stories: 1,000 examples\")\n",
    "    print(\"   âœ… code_samples: 500 examples\")\n",
    "    print(\"\")\n",
    "    print(\"ğŸ¯ Training on tiny_stories...\")\n",
    "    print(\"   ğŸ“Š Dashboard: Real-time loss curves, layer utilization heatmaps\")\n",
    "    print(\"   ğŸ“Š Parameters: 347,394,048 â†’ 347,894,048 (growth occurred)\")\n",
    "    print(\"   ğŸ”” Alert: Layer growth event detected\")\n",
    "    print(\"   âœ… tiny_stories complete!\")\n",
    "    print(\"\")\n",
    "    print(\"ğŸ¯ Training on code_samples...\")\n",
    "    print(\"   ğŸ“Š Dashboard: Architecture visualization updated\")\n",
    "    print(\"   ğŸ“Š Parameters: 347,894,048 â†’ 348,394,048 (growth occurred)\")\n",
    "    print(\"   ğŸ”” Alert: Performance threshold reached\")\n",
    "    print(\"   âœ… code_samples complete!\")\n",
    "    print(\"\")\n",
    "    print(\"ğŸ‰ Training pipeline complete!\")\n",
    "    \n",
    "    if IN_COLAB:\n",
    "        print(\"ğŸŒ View comprehensive analytics at your public dashboard URL\")\n",
    "    else:\n",
    "        print(\"ğŸ“Š Final dashboard shows comprehensive training analytics\")\n",
    "    \n",
    "    print(\"ğŸ“„ Training report exported with growth timeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbfa1c1",
   "metadata": {},
   "source": [
    "## Step 8: Test the Trained Model\n",
    "\n",
    "Let's test our model (or demonstrate what testing would look like) with different task types to see how the adaptive context system works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693bfd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model generation with different tasks\n",
    "print(\"ğŸ§ª Testing Trained Model\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "test_prompts = {\n",
    "    \"story\": \"Once upon a time, in a magical forest\",\n",
    "    \"code\": \"# Python function to calculate factorial\\ndef factorial(n):\",\n",
    "    \"reasoning\": \"Let me solve this step by step. The problem is:\",\n",
    "    \"chat\": \"User: What's the weather like today?\\nAssistant:\"\n",
    "}\n",
    "\n",
    "for task_type, prompt in test_prompts.items():\n",
    "    print(f\"\\nğŸ¯ Testing {task_type} task:\")\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    \n",
    "    # Tokenize prompt\n",
    "    inputs = trainer.tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    \n",
    "    # Show what would happen with adaptive context\n",
    "    print(f\"Input tokens: {input_ids.shape[1]}\")\n",
    "    \n",
    "    if RUN_TRAINING:\n",
    "        # Actually test the trained model\n",
    "        trainer.model.eval()\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                # Generate response\n",
    "                generated = trainer.model.generate(\n",
    "                    input_ids,\n",
    "                    max_new_tokens=50,\n",
    "                    temperature=0.7,\n",
    "                    do_sample=True\n",
    "                )\n",
    "                \n",
    "                # Decode response\n",
    "                response = trainer.tokenizer.decode(generated[0], skip_special_tokens=True)\n",
    "                print(f\"Generated: {response[len(prompt):]}\")\n",
    "                \n",
    "                # Show context info\n",
    "                context_info = trainer.model.get_context_info()\n",
    "                print(f\"Context used: {context_info['current_context_length']:,} tokens\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Generation failed: {e}\")\n",
    "    else:\n",
    "        # Simulate what would happen\n",
    "        simulated_contexts = {\"story\": 2048, \"code\": 4096, \"reasoning\": 8192, \"chat\": 1024}\n",
    "        print(f\"Would adapt context to: {simulated_contexts[task_type]:,} tokens\")\n",
    "        print(f\"Would generate appropriate {task_type} response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c46680c",
   "metadata": {},
   "source": [
    "## Step 9: Configuration Tips and Best Practices\n",
    "\n",
    "Here are some tips for customizing your YAML training configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd33aa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration tips and best practices\n",
    "print(\"ğŸ’¡ YAML Configuration Tips\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "tips = {\n",
    "    \"Model Size\": {\n",
    "        \"Small (100M)\": \"hidden_size: 512, num_layers: 12\",\n",
    "        \"Medium (500M)\": \"hidden_size: 1024, num_layers: 24\", \n",
    "        \"Large (1B)\": \"hidden_size: 1536, num_layers: 32\"\n",
    "    },\n",
    "    \n",
    "    \"Context Lengths\": {\n",
    "        \"Short tasks\": \"max 4K tokens (chat, Q&A)\",\n",
    "        \"Medium tasks\": \"4K-16K tokens (code, creative)\",\n",
    "        \"Long tasks\": \"16K+ tokens (documents, reasoning)\"\n",
    "    },\n",
    "    \n",
    "    \"Growth Settings\": {\n",
    "        \"Conservative\": \"factor: 1.25, threshold: 0.95\",\n",
    "        \"Moderate\": \"factor: 1.5, threshold: 0.9\",\n",
    "        \"Aggressive\": \"factor: 2.0, threshold: 0.85\"\n",
    "    },\n",
    "    \n",
    "    \"Training Speed\": {\n",
    "        \"Fast prototyping\": \"small datasets, few steps\",\n",
    "        \"Full training\": \"complete datasets, many steps\", \n",
    "        \"Production\": \"multiple epochs, careful validation\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for category, options in tips.items():\n",
    "    print(f\"\\nğŸ”§ {category}:\")\n",
    "    for option, description in options.items():\n",
    "        print(f\"   {option}: {description}\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Common YAML patterns:\")\n",
    "print(\"\"\"\n",
    "# Full monitoring setup for research\n",
    "adaptive_context: \n",
    "  enabled: true\n",
    "growth:\n",
    "  enabled: true\n",
    "logging:\n",
    "  arbor_tracking:\n",
    "    enabled: true\n",
    "    save_dir: './training_logs'\n",
    "    dashboard_port: 8501\n",
    "    alerts:\n",
    "      enabled: true\n",
    "\n",
    "# Minimal setup for testing  \n",
    "adaptive_context:\n",
    "  enabled: false\n",
    "growth:\n",
    "  enabled: false\n",
    "logging:\n",
    "  arbor_tracking:\n",
    "    enabled: false\n",
    "  console:\n",
    "    enabled: true\n",
    "datasets:\n",
    "  - name: \"test\"\n",
    "    source: \"roneneldan/TinyStories\"\n",
    "    split: \"train[:100]\"\n",
    "\n",
    "# Production setup with full tracking\n",
    "logging:\n",
    "  arbor_tracking:\n",
    "    enabled: true\n",
    "    save_dir: './production_logs'\n",
    "    update_interval: 0.5\n",
    "    dashboard_port: 8501\n",
    "    alerts:\n",
    "      enabled: true\n",
    "      email_notifications: true\n",
    "      webhook_url: \"https://your-webhook-url.com\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f97ae4e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've learned how to use the Arbor YAML training system with real-time monitoring. Here's what we covered:\n",
    "\n",
    "### âœ… **What You Learned:**\n",
    "\n",
    "1. **ğŸ“‹ YAML Configuration** - How to create and customize training configs\n",
    "2. **ğŸ§  Adaptive Context** - Task-aware context window adaptation  \n",
    "3. **ğŸŒ± Dynamic Growth** - Parameter expansion during training\n",
    "4. **ğŸš€ Easy Training** - One-command training with `python train.py config.yaml`\n",
    "5. **ğŸ“Š Live Monitoring** - Real-time dashboard with training visualization\n",
    "6. **ğŸ§ª Testing & Validation** - How to test trained models\n",
    "\n",
    "### ğŸ¯ **Key Benefits:**\n",
    "\n",
    "- **Simple**: Just edit YAML, no complex code\n",
    "- **Powerful**: Full control over model architecture and training\n",
    "- **Smart**: Automatic context adaptation and parameter growth\n",
    "- **Visual**: Real-time dashboard with live metrics and architecture visualization\n",
    "- **Production Ready**: HuggingFace integration and comprehensive monitoring\n",
    "\n",
    "### ğŸš€ **Next Steps:**\n",
    "\n",
    "1. **Customize** your own YAML config for your use case\n",
    "2. **Train** with real datasets for your domain\n",
    "3. **Monitor** training with the Arbor dashboard at http://localhost:8501\n",
    "4. **Deploy** trained models to HuggingFace Hub\n",
    "\n",
    "### ğŸ“Š **Dashboard Features:**\n",
    "\n",
    "- **Live Metrics**: Training loss, learning rate, gradient norms in real-time\n",
    "- **Architecture View**: Interactive model visualization with layer utilization\n",
    "- **Growth Tracking**: Parameter and layer growth timeline\n",
    "- **Alert System**: Automatic notifications for training events\n",
    "- **Analytics**: Performance statistics and comprehensive reports\n",
    "\n",
    "The YAML trainer with Arbor dashboard makes it incredibly easy to experiment with cutting-edge transformer architectures while monitoring everything in real-time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa08be",
   "metadata": {},
   "source": [
    "## ğŸŒ Google Colab Users - Public Dashboard Access\n",
    "\n",
    "### ğŸ¯ **For Google Colab Users:**\n",
    "\n",
    "Since Google Colab doesn't allow direct access to `localhost`, we use **ngrok** to create a public tunnel to your dashboard.\n",
    "\n",
    "#### ğŸš€ **Quick Setup:**\n",
    "\n",
    "1. **Get ngrok token** (free): Go to [ngrok.com](https://ngrok.com) â†’ Sign up â†’ Get your auth token\n",
    "2. **Run the environment setup cells** above to detect Colab and install packages\n",
    "3. **Run the dashboard startup cell** - enter your ngrok token when prompted\n",
    "4. **Get your public URL** - a unique URL like `https://abc123.ngrok.io`\n",
    "5. **Monitor training** - click the public URL to access your dashboard from anywhere!\n",
    "\n",
    "#### ğŸ“Š **Dashboard Features in Colab:**\n",
    "\n",
    "- **ğŸ“± Mobile-Responsive**: Perfect for monitoring on your phone\n",
    "- **ğŸŒ Public Access**: Share the URL with team members\n",
    "- **ğŸ”„ Real-Time Updates**: Just like local development\n",
    "- **ğŸ“ˆ Full Analytics**: All features work identically\n",
    "\n",
    "#### âš ï¸ **Important Notes:**\n",
    "\n",
    "- **Public URL**: Free ngrok URLs are accessible by anyone with the link\n",
    "- **Session Timeout**: URLs expire when you restart the Colab session\n",
    "- **Data Privacy**: Consider ngrok Pro for password protection in production\n",
    "\n",
    "#### ğŸ’¡ **Pro Tips:**\n",
    "\n",
    "- Keep this notebook tab open while training runs\n",
    "- Bookmark the ngrok URL for easy access\n",
    "- Save important results to Google Drive\n",
    "- Consider upgrading to ngrok Pro for private URLs\n",
    "\n",
    "### ğŸ”— **URL Structure:**\n",
    "```\n",
    "Local: http://localhost:8501\n",
    "Colab: https://[random].ngrok.io\n",
    "```\n",
    "\n",
    "Both URLs provide identical dashboard functionality!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c65eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup and final info\n",
    "print(\"ğŸ§¹ Cleanup and Final Info\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Show created files\n",
    "created_files = [\n",
    "    \"configs/tutorial_config.yaml\",\n",
    "    \"training_logs/\" if 'training_monitor' in locals() else \"training_logs/ (would be created)\",\n",
    "    \"tutorial_output/\" if RUN_TRAINING else \"tutorial_output/ (would be created)\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ“ Files created during this tutorial:\")\n",
    "for file in created_files:\n",
    "    if Path(file).exists() or \"would be\" in file:\n",
    "        print(f\"   âœ… {file}\")\n",
    "\n",
    "# Environment-specific instructions\n",
    "if IN_COLAB:\n",
    "    print(f\"\\nğŸŒ Google Colab Instructions:\")\n",
    "    print(f\"=\" * 30)\n",
    "    \n",
    "    print(f\"ğŸ¯ To run training yourself:\")\n",
    "    print(f\"   1. Set RUN_TRAINING = True in the training execution cell\")\n",
    "    print(f\"   2. Make sure you've run the dashboard startup cells above\")\n",
    "    print(f\"   3. Use the public ngrok URL to monitor training\")\n",
    "    \n",
    "    print(f\"\\nğŸŒ Dashboard Access:\")\n",
    "    if 'PUBLIC_URL' in globals() and PUBLIC_URL:\n",
    "        print(f\"   ğŸ”— Current public URL: {PUBLIC_URL}\")\n",
    "        print(f\"   ğŸ“± Mobile-friendly and shareable\")\n",
    "    else:\n",
    "        print(f\"   ğŸš€ Run the 'Start Dashboard in Colab' cell to get public URL\")\n",
    "        print(f\"   ğŸ”‘ Remember to set your ngrok auth token\")\n",
    "    \n",
    "    print(f\"\\nâš ï¸ Colab Limitations:\")\n",
    "    print(f\"   â€¢ Dashboard URL changes each time you restart\")\n",
    "    print(f\"   â€¢ Free ngrok URLs are public (anyone with link can access)\")\n",
    "    print(f\"   â€¢ Session will timeout if inactive for too long\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ Tips for Colab:\")\n",
    "    print(f\"   â€¢ Keep this notebook tab open while training\")\n",
    "    print(f\"   â€¢ Save important results to Google Drive\")\n",
    "    print(f\"   â€¢ Consider ngrok Pro for password-protected URLs\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\nğŸ’» Local Development Instructions:\")\n",
    "    print(f\"=\" * 35)\n",
    "    \n",
    "    dashboard_port = tutorial_config['logging']['arbor_tracking']['dashboard_port']\n",
    "    \n",
    "    print(f\"ğŸ¯ To run training yourself:\")\n",
    "    print(f\"   1. Set RUN_TRAINING = True in cell 23\")\n",
    "    print(f\"   2. Or run: python train.py configs/tutorial_config.yaml\")\n",
    "\n",
    "    print(f\"\\nğŸŒ Dashboard Access (Local):\")\n",
    "    print(f\"   1. Start dashboard: streamlit run arbor/tracking/dashboard.py --server.port={dashboard_port}\")\n",
    "    print(f\"   2. Open browser: http://localhost:{dashboard_port}\")\n",
    "    print(f\"   3. Or use launcher: python launch_training_dashboard.py\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Dashboard Features (All Environments):\")\n",
    "print(f\"   â€¢ ğŸ“ˆ Live training metrics with real-time updates\")\n",
    "print(f\"   â€¢ ğŸ—ï¸ Interactive model architecture visualization\")\n",
    "print(f\"   â€¢ ğŸŒ± Parameter and layer growth tracking\")\n",
    "print(f\"   â€¢ ğŸ”” Alert system with configurable notifications\")\n",
    "print(f\"   â€¢ ğŸ“Š Performance analytics and export capabilities\")\n",
    "print(f\"   â€¢ ğŸ“± Mobile-responsive design (great for Colab!)\")\n",
    "\n",
    "print(f\"\\nğŸ”§ To customize:\")\n",
    "print(f\"   1. Edit configs/tutorial_config.yaml\")\n",
    "print(f\"   2. Adjust model size, datasets, training steps\")\n",
    "print(f\"   3. Enable/disable adaptive context and growth\")\n",
    "print(f\"   4. Configure dashboard alerts and monitoring\")\n",
    "\n",
    "print(f\"\\nğŸ“š For more examples:\")\n",
    "print(f\"   â€¢ Check configs/example_config.yaml\")\n",
    "if not IN_COLAB:\n",
    "    print(f\"   â€¢ Run python examples/training_with_dashboard.py\")\n",
    "    print(f\"   â€¢ See COMPLETE_USAGE_GUIDE.md for full documentation\")\n",
    "else:\n",
    "    print(f\"   â€¢ Upload examples to Colab for local exploration\")\n",
    "    print(f\"   â€¢ Check the GitHub repo for complete documentation\")\n",
    "\n",
    "print(f\"\\nğŸŒ± Happy training with Arbor and live monitoring!\")\n",
    "if IN_COLAB:\n",
    "    print(f\"ğŸŒ Perfect for Google Colab with public dashboard access!\")\n",
    "else:\n",
    "    print(f\"ğŸš€ The future of adaptive AI training is here!\")\n",
    "\n",
    "# Show ngrok tunnel info if in Colab\n",
    "if IN_COLAB and 'PUBLIC_URL' in globals() and PUBLIC_URL:\n",
    "    print(f\"\\nğŸ”— Current Dashboard: {PUBLIC_URL}\")\n",
    "    print(f\"ğŸ’¾ Bookmark this URL to monitor your training!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
